name: Build library

on:
  push:
    tags:
      - 'v*'

env:
  CUDA: 12.4.1

jobs:
  ################################ Linux ################################

  linux-build:
    runs-on: ubuntu-22.04

    strategy:
      matrix:
        include:
          - arch: linux-x64_noavx
          - arch: linux-x64_avx2
          - arch: linux-x64_avx
          - arch: linux-x64_avx512
          - arch: linux-x64_vulkan
          - arch: linux-x64_tinyblas
          - arch: linux-x64_cublas
            
    steps:
        - id: setup_libs_linux
          name: Dependencies
          run: |
            sudo apt-get update
            sudo apt-get install -y build-essential cmake zip libssl-dev git libcurl4-openssl-dev curl

        - id: checkout
          name: Clone
          uses: actions/checkout@v4
          with:
            submodules: recursive

        - id: preparation
          name: Preparation
          run: |
            mkdir -p build/libs
            echo "CMAKE_VARS=-DARCHITECTURE=${{ matrix.arch }} -DCMAKE_RUNTIME_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_ARCHIVE_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs ${{ matrix.cmake_vars }}" >> $GITHUB_ENV
          shell: bash

        - id: setup_vulkan_linux
          if: contains(matrix.arch, 'vulkan')
          name: Dependencies Vulcan
          run: |
            wget -qO - https://packages.lunarg.com/lunarg-signing-key-pub.asc | sudo apt-key add -
            sudo wget -qO /etc/apt/sources.list.d/lunarg-vulkan-jammy.list https://packages.lunarg.com/vulkan/lunarg-vulkan-jammy.list
            sudo apt-get update -y
            sudo apt-get install -y build-essential vulkan-sdk
            cp /lib/x86_64-linux-gnu/libvulkan.so.1 build/libs/

        - id: setup_cuda_linux
          if: contains(matrix.arch, 'blas')
          uses: Jimver/cuda-toolkit@v0.2.15
          with:
            cuda: ${{ env.CUDA }}
            linux-local-args: '["--toolkit"]'
            method: network

        - id: link_cuda_linux
          if: contains(matrix.arch, 'blas')
          name: Link Cuda
          run: |
            ln -s ${{ env.CUDA_PATH }} ${{ github.workspace }}/build/cuda
            echo "CUDAToolkit_ROOT=$GITHUB_WORKSPACE/build/cuda" >> $GITHUB_ENV
            echo "LD_LIBRARY_PATH=''" >> $GITHUB_ENV


        - id: cpu-cores
          name: Get number of CPU cores
          uses: SimenB/github-actions-cpu-cores@v2

        - id: cmake_build
          name: Build
          run: |
            cd build
            cmake .. ${{ env.CMAKE_VARS }}
            cmake --build . --config Release -j ${{ steps.cpu-cores.outputs.count }}

        - id: test_build
          if: contains(matrix.arch, 'noavx') || contains(matrix.arch, 'avx2') || contains(matrix.arch, 'osx')
          name: Test
          run: |
            cd build/libs
            EXE=""
            if [[ "$RUNNER_OS" == "Windows" ]]; then
              cd Release
              EXE=".exe"
            fi
        
            curl -L -o model.gguf "https://huggingface.co/afrideva/smol_llama-220M-openhermes-GGUF/resolve/main/smol_llama-220m-openhermes.q4_k_m.gguf?download=true"
        
            ./llamalib_tests$EXE -m model.gguf -np 1 --log-disable
            ./llamalib_tests_runtime$EXE -m model.gguf -np 1 --log-disable
        
            rm model.gguf
          shell: bash


        - id: pack_artifacts
          name: Pack artifacts
          run: |
            ls -R build
        
            mkdir -p artifacts
            mv build/Release/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/Release/*llamalib* artifacts/ 2>/dev/null || true
            rm -f artifacts/*llamalib_tests* artifacts/*exp artifacts/*server*lib 2>/dev/null || true
        
            cd artifacts
            if [[ "$RUNNER_OS" == "Windows" ]]; then
              7z a ../${{ matrix.arch }}.zip *
            else
              zip ../${{ matrix.arch }}.zip *
            fi
          shell: bash

        - id: upload_llamalib
          name: Upload Artifacts
          uses: actions/upload-artifact@v4
          with:
            name: ${{ matrix.arch }}.zip
            path: ${{ matrix.arch }}.zip



  linux-hip-build:
    runs-on: ubuntu-22.04
    container: rocm/dev-ubuntu-22.04:5.5

    strategy:
      matrix:
        include:
          - arch: linux-x64_hip

    defaults:
      run:
        working-directory: /home/runner/work/LlamaLib/LlamaLib

    steps:
        - id: setup_libs_linux
          name: Dependencies
          run: |
            sudo apt-get update
            sudo apt-get install -y build-essential cmake zip libssl-dev git libcurl4-openssl-dev curl

        - id: checkout
          name: Clone
          uses: actions/checkout@v4
          with:
            submodules: recursive

        - id: preparation
          name: Preparation
          run: |
            mkdir -p build/libs
            echo "CMAKE_VARS=-DARCHITECTURE=${{ matrix.arch }} -DCMAKE_RUNTIME_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_ARCHIVE_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs ${{ matrix.cmake_vars }}" >> $GITHUB_ENV
          shell: bash

        - id: setup_hip_linux
          name: Dependencies
          run: |
            sudo apt-get install -y rocblas-dev hipblas-dev
            echo "CMAKE_VARS=$(echo $CMAKE_VARS | sed "s|${{ github.workspace }}/|$(pwd)/|g") -DCMAKE_HIP_COMPILER=$(hipconfig -l)/clang" >> $GITHUB_ENV


        - id: cpu-cores
          name: Get number of CPU cores
          uses: SimenB/github-actions-cpu-cores@v2

        - id: cmake_build
          name: Build
          run: |
            cd build
            cmake .. ${{ env.CMAKE_VARS }}
            cmake --build . --config Release -j ${{ steps.cpu-cores.outputs.count }}


        - id: pack_artifacts
          name: Pack artifacts
          run: |
            ls -R build
        
            mkdir -p artifacts
            mv build/Release/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/Release/*llamalib* artifacts/ 2>/dev/null || true
            rm -f artifacts/*llamalib_tests* artifacts/*exp artifacts/*server*lib 2>/dev/null || true
        
            cd artifacts
            if [[ "$RUNNER_OS" == "Windows" ]]; then
              7z a ../${{ matrix.arch }}.zip *
            else
              zip ../${{ matrix.arch }}.zip *
            fi
          shell: bash

        - id: upload_llamalib
          name: Upload Artifacts
          uses: actions/upload-artifact@v4
          with:
            name: ${{ matrix.arch }}.zip
            path: ${{ matrix.arch }}.zip


################################ macOS ################################

  osx-arm64-build:
    runs-on: macos-14

    strategy:
      matrix:
        include:
          - arch: osx-arm64_acc
          - arch: osx-arm64_no-acc

    steps:
        - continue-on-error: true
          id: setup_libs_macos
          name: Dependencies
          run: |
            echo "Architecture: $(uname -m)"
            echo "Operating System: $(uname -s)"
            brew update

        - id: checkout
          name: Clone
          uses: actions/checkout@v4
          with:
            submodules: recursive

        - id: preparation
          name: Preparation
          run: |
            mkdir -p build/libs
            echo "CMAKE_VARS=-DARCHITECTURE=${{ matrix.arch }} -DCMAKE_RUNTIME_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_ARCHIVE_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs ${{ matrix.cmake_vars }}" >> $GITHUB_ENV
          shell: bash


        - id: cpu-cores
          name: Get number of CPU cores
          uses: SimenB/github-actions-cpu-cores@v2

        - id: cmake_build
          name: Build
          run: |
            cd build
            cmake .. ${{ env.CMAKE_VARS }}
            cmake --build . --config Release -j ${{ steps.cpu-cores.outputs.count }}

        - id: test_build
          if: contains(matrix.arch, 'noavx') || contains(matrix.arch, 'avx2') || contains(matrix.arch, 'osx')
          name: Test
          run: |
            cd build/libs
            EXE=""
            if [[ "$RUNNER_OS" == "Windows" ]]; then
              cd Release
              EXE=".exe"
            fi
        
            curl -L -o model.gguf "https://huggingface.co/afrideva/smol_llama-220M-openhermes-GGUF/resolve/main/smol_llama-220m-openhermes.q4_k_m.gguf?download=true"
        
            ./llamalib_tests$EXE -m model.gguf -np 1 --log-disable
            ./llamalib_tests_runtime$EXE -m model.gguf -np 1 --log-disable
        
            rm model.gguf
          shell: bash


        - id: pack_artifacts
          name: Pack artifacts
          run: |
            ls -R build
        
            mkdir -p artifacts
            mv build/Release/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/Release/*llamalib* artifacts/ 2>/dev/null || true
            rm -f artifacts/*llamalib_tests* artifacts/*exp artifacts/*server*lib 2>/dev/null || true
        
            cd artifacts
            if [[ "$RUNNER_OS" == "Windows" ]]; then
              7z a ../${{ matrix.arch }}.zip *
            else
              zip ../${{ matrix.arch }}.zip *
            fi
          shell: bash

        - id: upload_llamalib
          name: Upload Artifacts
          uses: actions/upload-artifact@v4
          with:
            name: ${{ matrix.arch }}.zip
            path: ${{ matrix.arch }}.zip


  osx-x64-build:
    runs-on: macos-13

    strategy:
      matrix:
        include:
          - arch: osx-x64_acc
          - arch: osx-x64_no-acc

    steps:
        - continue-on-error: true
          id: setup_libs_macos
          name: Dependencies
          run: |
            echo "Architecture: $(uname -m)"
            echo "Operating System: $(uname -s)"
            brew update

        - id: checkout
          name: Clone
          uses: actions/checkout@v4
          with:
            submodules: recursive

        - id: preparation
          name: Preparation
          run: |
            mkdir -p build/libs
            echo "CMAKE_VARS=-DARCHITECTURE=${{ matrix.arch }} -DCMAKE_RUNTIME_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_ARCHIVE_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs ${{ matrix.cmake_vars }}" >> $GITHUB_ENV
          shell: bash


        - id: cpu-cores
          name: Get number of CPU cores
          uses: SimenB/github-actions-cpu-cores@v2

        - id: cmake_build
          name: Build
          run: |
            cd build
            cmake .. ${{ env.CMAKE_VARS }}
            cmake --build . --config Release -j ${{ steps.cpu-cores.outputs.count }}

        - id: test_build
          if: contains(matrix.arch, 'noavx') || contains(matrix.arch, 'avx2') || contains(matrix.arch, 'osx')
          name: Test
          run: |
            cd build/libs
            EXE=""
            if [[ "$RUNNER_OS" == "Windows" ]]; then
              cd Release
              EXE=".exe"
            fi
        
            curl -L -o model.gguf "https://huggingface.co/afrideva/smol_llama-220M-openhermes-GGUF/resolve/main/smol_llama-220m-openhermes.q4_k_m.gguf?download=true"
        
            ./llamalib_tests$EXE -m model.gguf -np 1 --log-disable
            ./llamalib_tests_runtime$EXE -m model.gguf -np 1 --log-disable
        
            rm model.gguf
          shell: bash


        - id: pack_artifacts
          name: Pack artifacts
          run: |
            ls -R build
        
            mkdir -p artifacts
            mv build/Release/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/Release/*llamalib* artifacts/ 2>/dev/null || true
            rm -f artifacts/*llamalib_tests* artifacts/*exp artifacts/*server*lib 2>/dev/null || true
        
            cd artifacts
            if [[ "$RUNNER_OS" == "Windows" ]]; then
              7z a ../${{ matrix.arch }}.zip *
            else
              zip ../${{ matrix.arch }}.zip *
            fi
          shell: bash

        - id: upload_llamalib
          name: Upload Artifacts
          uses: actions/upload-artifact@v4
          with:
            name: ${{ matrix.arch }}.zip
            path: ${{ matrix.arch }}.zip



################################ Windows ################################

  windows-build:
    runs-on: windows-2022

    env:
      VULKAN_VERSION: 1.3.261.1
      PLATFORM: windows

    strategy:
      matrix:
        include:
          - arch: win-x64_noavx
          - arch: win-x64_avx2
          - arch: win-x64_avx
          - arch: win-x64_avx512
          - arch: win-x64_vulkan
          - arch: win-x64_tinyblas
          - arch: win-x64_cublas

    steps:
        - id: checkout
          name: Clone
          uses: actions/checkout@v4
          with:
            submodules: recursive

        - id: preparation
          name: Preparation
          run: |
            mkdir -p build/libs
            echo "CMAKE_VARS=-DARCHITECTURE=${{ matrix.arch }} -DCMAKE_RUNTIME_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_ARCHIVE_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs ${{ matrix.cmake_vars }}" >> $GITHUB_ENV
          shell: bash

        - id: setup_vulcan_windows
          if: contains(matrix.arch, 'vulkan')
          name: Install Vulkan SDK
          run: |
            mkdir -p .\build\libs\Release
            curl.exe -o $env:RUNNER_TEMP/VulkanSDK-Installer.exe -L "https://sdk.lunarg.com/sdk/download/${env:VULKAN_VERSION}/windows/VulkanSDK-${env:VULKAN_VERSION}-Installer.exe"
            & "$env:RUNNER_TEMP\VulkanSDK-Installer.exe" --accept-licenses --default-answer --confirm-command install
            Add-Content $env:GITHUB_ENV "VULKAN_SDK=C:\VulkanSDK\${env:VULKAN_VERSION}"
            Add-Content $env:GITHUB_PATH "C:\VulkanSDK\${env:VULKAN_VERSION}\bin"
            curl.exe -o $env:RUNNER_TEMP/VulkanRT-Components.zip -L "https://sdk.lunarg.com/sdk/download/1.3.283.0/windows/VulkanRT-1.3.283.0-Components.zip"
            7z x "-o${env:RUNNER_TEMP}" $env:RUNNER_TEMP/VulkanRT-Components.zip
            cp ${env:RUNNER_TEMP}/VulkanRT*\x64\vulkan-1.dll .\build\libs\Release

        - id: setup_openssl_windows
          name: Install OpenSSL
          run: |
            choco install openssl --no-progress
            $OPENSSL_ROOT_DIR = 'C:\Program Files\OpenSSL'
            Copy-Item $OPENSSL_ROOT_DIR\lib\VC\x64\MD\*.lib $OPENSSL_ROOT_DIR\lib\
            Copy-Item $OPENSSL_ROOT_DIR\lib\libcrypto_static.lib $OPENSSL_ROOT_DIR\lib\libcrypto.a
            Copy-Item $OPENSSL_ROOT_DIR\lib\libssl_static.lib $OPENSSL_ROOT_DIR\lib\libssl.a
            Add-Content $env:GITHUB_ENV "OPENSSL_ROOT_DIR=$OPENSSL_ROOT_DIR"

        - id: setup_cuda_windows
          if: contains(matrix.arch, 'blas')
          uses: Jimver/cuda-toolkit@v0.2.15
          with:
            cuda: ${{ env.CUDA }}
            method: network
            sub-packages: '["nvcc", "cudart", "cublas", "cublas_dev", "thrust", "visual_studio_integration"]'


        - id: cpu-cores
          name: Get number of CPU cores
          uses: SimenB/github-actions-cpu-cores@v2

        - id: cmake_build
          name: Build
          run: |
            cd build
            cmake .. ${{ env.CMAKE_VARS }}
            cmake --build . --config Release -j ${{ steps.cpu-cores.outputs.count }}

        - id: test_build
          if: contains(matrix.arch, 'noavx') || contains(matrix.arch, 'avx2') || contains(matrix.arch, 'osx')
          name: Test
          run: |
            cd build/libs
            EXE=""
            if [[ "$RUNNER_OS" == "Windows" ]]; then
              cd Release
              EXE=".exe"
            fi
        
            curl -L -o model.gguf "https://huggingface.co/afrideva/smol_llama-220M-openhermes-GGUF/resolve/main/smol_llama-220m-openhermes.q4_k_m.gguf?download=true"
        
            ./llamalib_tests$EXE -m model.gguf -np 1 --log-disable
            ./llamalib_tests_runtime$EXE -m model.gguf -np 1 --log-disable
        
            rm model.gguf
          shell: bash


        - id: copy_cuda_dlls
          if: contains(matrix.arch, 'cublas')
          name: Copy Cuda DLLs
          run: |
            mv "${{ env.CUDA_PATH }}"/bin/cudart64_*.dll build/libs/Release
            mv "${{ env.CUDA_PATH }}"/bin/cublas64_*.dll build/libs/Release
            mv "${{ env.CUDA_PATH }}"/bin/cublasLt64_*.dll build/libs/Release
          shell: bash

        - id: pack_artifacts
          name: Pack artifacts
          run: |
            ls -R build
        
            mkdir -p artifacts
            mv build/Release/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/Release/*llamalib* artifacts/ 2>/dev/null || true
            rm -f artifacts/*llamalib_tests* artifacts/*exp artifacts/*server*lib 2>/dev/null || true
        
            cd artifacts
            if [[ "$RUNNER_OS" == "Windows" ]]; then
              7z a ../${{ matrix.arch }}.zip *
            else
              zip ../${{ matrix.arch }}.zip *
            fi
          shell: bash

        - id: upload_llamalib
          name: Upload Artifacts
          uses: actions/upload-artifact@v4
          with:
            name: ${{ matrix.arch }}.zip
            path: ${{ matrix.arch }}.zip


  windows-hip-build:
    runs-on: windows-2022

    env:
      PLATFORM: windows
    
    strategy:
      matrix:
        include:
          - arch: win-x64_hip

    steps:
        - id: checkout
          name: Clone
          uses: actions/checkout@v4
          with:
            submodules: recursive

        - id: preparation
          name: Preparation
          run: |
            mkdir -p build/libs
            echo "CMAKE_VARS=-DARCHITECTURE=${{ matrix.arch }} -DCMAKE_RUNTIME_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_ARCHIVE_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs ${{ matrix.cmake_vars }}" >> $GITHUB_ENV
          shell: bash

        - id: setup_openssl_windows
          name: Install OpenSSL
          run: |
            choco install openssl --no-progress
            $OPENSSL_ROOT_DIR = 'C:\Program Files\OpenSSL'
            Copy-Item $OPENSSL_ROOT_DIR\lib\VC\x64\MD\*.lib $OPENSSL_ROOT_DIR\lib\
            Copy-Item $OPENSSL_ROOT_DIR\lib\libcrypto_static.lib $OPENSSL_ROOT_DIR\lib\libcrypto.a
            Copy-Item $OPENSSL_ROOT_DIR\lib\libssl_static.lib $OPENSSL_ROOT_DIR\lib\libssl.a
            Add-Content $env:GITHUB_ENV "OPENSSL_ROOT_DIR=$OPENSSL_ROOT_DIR"

        - id: setup_hip_windows
          name: Install
          run: |
            git clone https://github.com/rocm/rocwmma --branch rocm-6.2.4 --depth 1
            $ErrorActionPreference = "Stop"
            write-host "Downloading AMD HIP SDK Installer"
            Invoke-WebRequest -Uri "https://download.amd.com/developer/eula/rocm-hub/AMD-Software-PRO-Edition-24.Q3-WinSvr2022-For-HIP.exe" -OutFile "${env:RUNNER_TEMP}\rocm-install.exe"
            write-host "Installing AMD HIP SDK"
            Start-Process "${env:RUNNER_TEMP}\rocm-install.exe" -ArgumentList '-install' -NoNewWindow -Wait
            write-host "Completed AMD HIP SDK installation"
            & 'C:\Program Files\AMD\ROCm\*\bin\clang.exe' --version


        - id: cpu-cores
          name: Get number of CPU cores
          uses: SimenB/github-actions-cpu-cores@v2

        - id: cmake_build_hip_windows
          name: Build
          run: |
            $env:HIP_PATH=$(Resolve-Path 'C:\Program Files\AMD\ROCm\*\bin\clang.exe' | split-path | split-path)
            $env:CMAKE_PREFIX_PATH="${env:HIP_PATH}"
            cd build
            cmake -G "Unix Makefiles" .. -DCMAKE_C_COMPILER="${env:HIP_PATH}\bin\clang.exe" -DCMAKE_CXX_COMPILER="${env:HIP_PATH}\bin\clang++.exe" -DCMAKE_CXX_FLAGS="-I$($PWD.Path.Replace('\', '/'))/rocwmma/library/include/" ${{ env.CMAKE_VARS }}
            cmake --build . --config Release -j ${{ steps.cpu-cores.outputs.count }}
            mkdir Release


        - id: pack_artifacts
          name: Pack artifacts
          run: |
            ls -R build
        
            mkdir -p artifacts
            mv build/Release/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/Release/*llamalib* artifacts/ 2>/dev/null || true
            rm -f artifacts/*llamalib_tests* artifacts/*exp artifacts/*server*lib 2>/dev/null || true
        
            cd artifacts
            if [[ "$RUNNER_OS" == "Windows" ]]; then
              7z a ../${{ matrix.arch }}.zip *
            else
              zip ../${{ matrix.arch }}.zip *
            fi
          shell: bash

        - id: upload_llamalib
          name: Upload Artifacts
          uses: actions/upload-artifact@v4
          with:
            name: ${{ matrix.arch }}.zip
            path: ${{ matrix.arch }}.zip


################################ Android ################################

  android-build:
    runs-on: ubuntu-22.04

    strategy:
      matrix:
        include:
          - arch: android-arm64
            ABI: arm64-v8a
          - arch: android-x64
            ABI: x86_64

    steps:
        - id: setup_libs_linux
          name: Dependencies
          run: |
            sudo apt-get update
            sudo apt-get install -y build-essential cmake zip libssl-dev git libcurl4-openssl-dev curl

        - id: checkout
          name: Clone
          uses: actions/checkout@v4
          with:
            submodules: recursive

        - id: preparation
          name: Preparation
          run: |
            mkdir -p build/libs
            echo "CMAKE_VARS=-DARCHITECTURE=${{ matrix.arch }} -DCMAKE_RUNTIME_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_ARCHIVE_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs ${{ matrix.cmake_vars }}" >> $GITHUB_ENV
          shell: bash


        - id: cpu-cores
          name: Get number of CPU cores
          uses: SimenB/github-actions-cpu-cores@v2

        - id: build_openssl
          name: Build OpenSSL
          run: |
            .github/scripts/build_openssl.sh ${{ matrix.arch }}

        - id: cmake_build_android
          name: Build
          run: |
            export LD_LIBRARY_PATH=""
            export NDK=`ls -d /usr/local/lib/android/sdk/ndk/26.*`
            cd build
            cmake .. -DCMAKE_TOOLCHAIN_FILE=$NDK/build/cmake/android.toolchain.cmake -DANDROID_PLATFORM=android-23 -DANDROID_ABI=${{ matrix.ABI }} ${{ env.CMAKE_VARS }}
            cmake --build . --config Release -j ${{ steps.cpu-cores.outputs.count }}


        - id: pack_artifacts
          name: Pack artifacts
          run: |
            ls -R build
        
            mkdir -p artifacts
            mv build/Release/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/Release/*llamalib* artifacts/ 2>/dev/null || true
            rm -f artifacts/*llamalib_tests* artifacts/*exp artifacts/*server*lib 2>/dev/null || true
        
            cd artifacts
            if [[ "$RUNNER_OS" == "Windows" ]]; then
              7z a ../${{ matrix.arch }}.zip *
            else
              zip ../${{ matrix.arch }}.zip *
            fi
          shell: bash

        - id: upload_llamalib
          name: Upload Artifacts
          uses: actions/upload-artifact@v4
          with:
            name: ${{ matrix.arch }}.zip
            path: ${{ matrix.arch }}.zip


################################ iOS ################################

  ios-build:
    runs-on: macos-14

    strategy:
      matrix:
        include:
          - arch: ios-arm64
            cmake_vars: '-DCMAKE_SYSTEM_NAME=iOS'
          - arch: visionos-arm64
            cmake_vars: '-DCMAKE_SYSTEM_NAME=visionOS'

    steps:
        - continue-on-error: true
          id: setup_libs_macos
          name: Dependencies
          run: |
            echo "Architecture: $(uname -m)"
            echo "Operating System: $(uname -s)"
            brew update

        - id: checkout
          name: Clone
          uses: actions/checkout@v4
          with:
            submodules: recursive

        - id: preparation
          name: Preparation
          run: |
            mkdir -p build/libs
            echo "CMAKE_VARS=-DARCHITECTURE=${{ matrix.arch }} -DCMAKE_RUNTIME_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_ARCHIVE_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs ${{ matrix.cmake_vars }}" >> $GITHUB_ENV
          shell: bash


        - id: cpu-cores
          name: Get number of CPU cores
          uses: SimenB/github-actions-cpu-cores@v2

        - id: build_openssl
          name: Build OpenSSL
          run: |
            .github/scripts/build_openssl.sh ${{ matrix.arch }}

        - id: cmake_build
          name: Build
          run: |
            cd build
            cmake .. ${{ env.CMAKE_VARS }}
            cmake --build . --config Release -j ${{ steps.cpu-cores.outputs.count }}

        - id: link_libraries_ios
          name: Link libraries
          run: |
            mkdir -p build/combo build/libs
            cd build/combo
            for f in `find .. -name "*.a"`;do ar -x $f;done
            lib=../libs/libllamalib_${{ matrix.arch }}.a
            ld -r -o $lib *.o
            nm -u $lib


        - id: pack_artifacts
          name: Pack artifacts
          run: |
            ls -R build
        
            mkdir -p artifacts
            mv build/Release/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/*llamalib* artifacts/ 2>/dev/null || true
            mv build/libs/Release/*llamalib* artifacts/ 2>/dev/null || true
            rm -f artifacts/*llamalib_tests* artifacts/*exp artifacts/*server*lib 2>/dev/null || true
        
            cd artifacts
            if [[ "$RUNNER_OS" == "Windows" ]]; then
              7z a ../${{ matrix.arch }}.zip *
            else
              zip ../${{ matrix.arch }}.zip *
            fi
          shell: bash

        - id: upload_llamalib
          name: Upload Artifacts
          uses: actions/upload-artifact@v4
          with:
            name: ${{ matrix.arch }}.zip
            path: ${{ matrix.arch }}.zip


################################ Release ################################

  create_release:
    name: Create Release
    runs-on: ubuntu-22.04
    needs:
      - linux-build
      - linux-hip-build
      - osx-arm64-build
      - osx-x64-build
      - windows-build
      - windows-hip-build
      - android-build
      - ios-build
    steps:
        - id: checkout
          name: Clone
          uses: actions/checkout@v4
          with:
            submodules: recursive

        - id: set_release_version
          name: Set version
          run: |
            VERSION=${GITHUB_REF_NAME#v}
            echo "VERSION=$VERSION" >> $GITHUB_ENV
            echo "RELEASE_NAME=LlamaLib-v$VERSION" >> $GITHUB_ENV
            echo "$VERSION" > VERSION
            sed -i "s|<PackageVersion>.*</PackageVersion>|<PackageVersion>${VERSION}</PackageVersion>|g" csharp/LlamaLib.csproj
            sed -i "s|<LlamaLibVersion>.*</LlamaLibVersion>|<LlamaLibVersion>${VERSION}</LlamaLibVersion>|g" csharp/LlamaLib.targets
            sed -i "s|\(Include=\"LlamaLib\" Version=\)\"[^\"]*\"|\1\"${VERSION}\"|g" tests/csharp/LlamaLib.Test.csproj
          shell: bash

        - id: download_artifacts
          name: Download Artifacts
          uses: actions/download-artifact@v4
          with:
            path: release

        - id: structure_artifacts
          name: Unzip and combine artifacts
          run: |
            cd release
            ls -R
        
            mkdir servers
            for arch in win-x64_noavx linux-x64_noavx osx-arm64_no-acc osx-x64_no-acc;do
              unzip -o $arch.zip/$arch.zip -d servers llamalib*server*
              platform=`echo $arch|cut -d'_' -f1`
              source=`ls servers/llamalib_${platform}_server*`
              target=`echo $source|sed -e "s:$arch:$platform:g"`
              mv $source $target
            done
        
            for d in *.zip;do
              platform=`echo $d|cut -d'.' -f1|cut -d'_' -f1`
              mkdir -p runtimes/$platform/native
              unzip -o $d/$d -d runtimes/$platform/native -x llamalib*server*
              rm -r $d
            done

        - id: create_release
          name: Create release
          run: |
            ./.github/scripts/release.sh release
            mv release ${{ env.RELEASE_NAME }}
            zip -r ${{ env.RELEASE_NAME }}.zip ${{ env.RELEASE_NAME }}

        - id: pack_nuget
          name: Pack nuget
          run: |
            cd csharp
            dotnet pack -c Release

        - id: test_nuget
          name: Test nuget
          run: |
            mkdir -p ~/.nuget/packages/LlamaLib
            ln -s ${{ env.RELEASE_NAME }}.zip ~/.nuget/packages/LlamaLib/${{ env.RELEASE_NAME }}.zip
        
            cd tests
            curl -L -o model.gguf https://huggingface.co/afrideva/smol_llama-220M-openhermes-GGUF/resolve/main/smol_llama-220m-openhermes.q4_k_m.gguf?download=true
        
            cd csharp
            dotnet build -c Release
            dotnet test -c Release

        - id: release
          name: Release
          uses: softprops/action-gh-release@v2
          with:
            files: |
              ${{ env.RELEASE_NAME }}.zip
              csharp/bin/Release/LlamaLib*nupkg
            name: Release ${{ env.VERSION }}


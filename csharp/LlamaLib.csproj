<Project Sdk="Microsoft.NET.Sdk">

  <!-- ===================== -->
  <!--  General properties  -->
  <!-- ===================== -->
  <PropertyGroup>
    <TargetFrameworks>netstandard2.0;net6.0;net8.0</TargetFrameworks>
    <LangVersion>latest</LangVersion>
    <AllowUnsafeBlocks>true</AllowUnsafeBlocks>

    <IncludeSymbols>true</IncludeSymbols>
    <SymbolPackageFormat>snupkg</SymbolPackageFormat>

    <!-- NuGet metadata -->
    <PackageId>LlamaLib</PackageId>
    <PackageVersion>2.0.2</PackageVersion>
    <Authors>Antonis Makropoulos</Authors>
    <Company>UndreamAI</Company>
    <Description>LlamaLib - Cross-Platform High-Level LLM Library</Description>
    <PackageProjectUrl>https://undream.ai</PackageProjectUrl>
    <PackageLicenseExpression>Apache-2.0</PackageLicenseExpression>
    <PackageReadmeFile>README.md</PackageReadmeFile>
    <RepositoryUrl>https://github.com/undreamai/LlamaLib</RepositoryUrl>
    <RepositoryType>git</RepositoryType>
    <PackageTags>llm;ai;llama;local-llm;gguf;inference;chatbot;nlp;transformers;llama-cpp;rag</PackageTags>
  </PropertyGroup>

  <!-- ===================== -->
  <!--  Architecture flags  -->
  <!-- ===================== -->
  <!-- Mirrors CMake LLAMALIB_USE_* options -->

  <PropertyGroup>
    <!-- Global CPU/GPU toggles -->
    <LlamaLibAllowCPU Condition="'$(LlamaLibAllowCPU)' == ''">true</LlamaLibAllowCPU>
    <LlamaLibAllowGPU Condition="'$(LlamaLibAllowGPU)' == ''">true</LlamaLibAllowGPU>

    <!-- CPU -->
    <LlamaLibUseAvx512 Condition="'$(LlamaLibUseAvx512)' == ''">true</LlamaLibUseAvx512>
    <LlamaLibUseAvx2   Condition="'$(LlamaLibUseAvx2)'   == ''">true</LlamaLibUseAvx2>
    <LlamaLibUseAvx    Condition="'$(LlamaLibUseAvx)'    == ''">true</LlamaLibUseAvx>
    <LlamaLibUseNoAvx  Condition="'$(LlamaLibUseNoAvx)'  == ''">true</LlamaLibUseNoAvx>

    <!-- GPU -->
    <LlamaLibUseCublas   Condition="'$(LlamaLibUseCublas)'   == ''">true</LlamaLibUseCublas>
    <LlamaLibUseTinyblas Condition="'$(LlamaLibUseTinyblas)' == ''">false</LlamaLibUseTinyblas>
    <LlamaLibUseVulkan   Condition="'$(LlamaLibUseVulkan)'   == ''">true</LlamaLibUseVulkan>
    <LlamaLibUseHip      Condition="'$(LlamaLibUseHip)'      == ''">true</LlamaLibUseHip>

    <!-- Accelerate -->
    <LlamaLibUseAccelerate Condition="'$(LlamaLibUseAccelerate)' == ''">true</LlamaLibUseAccelerate>
    <LlamaLibUseNoAccelerate Condition="'$(LlamaLibUseNoAccelerate)' == ''">true</LlamaLibUseNoAccelerate>
    <LlamaLibUseIOS Condition="'$(LlamaLibUseIOS)' == ''">false</LlamaLibUseIOS>
    <LlamaLibVisionOS Condition="'$(LlamaLibVisionOS)' == ''">false</LlamaLibVisionOS>
  </PropertyGroup>

  <!-- ===================== -->
  <!--  OS defines (managed) -->
  <!-- ===================== -->
  <PropertyGroup>
    <DefineConstants Condition="$([MSBuild]::IsOSPlatform('Windows'))">WINDOWS</DefineConstants>
    <DefineConstants Condition="$([MSBuild]::IsOSPlatform('Linux'))">LINUX</DefineConstants>
    <DefineConstants Condition="$([MSBuild]::IsOSPlatform('OSX'))">OSX</DefineConstants>
  </PropertyGroup>

  <!-- ===================== -->
  <!--  Package assets       -->
  <!-- ===================== -->
  <ItemGroup>
    <None Include="LlamaLib.targets" Pack="true" PackagePath="build\" />
    <None Include="LlamaLib.targets" Pack="true" PackagePath="buildTransitive\" />
    <None Include="README.md" Pack="true" PackagePath="\" />
  </ItemGroup>

  <ItemGroup>
    <PackageReference Include="Newtonsoft.Json" Version="13.0.3" />
  </ItemGroup>

</Project>
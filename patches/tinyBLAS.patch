diff --git a/ggml/src/ggml-cuda/CMakeLists.txt b/ggml/src/ggml-cuda/CMakeLists.txt
index 67af1d8cc..2e961c006 100644
--- a/ggml/src/ggml-cuda/CMakeLists.txt
+++ b/ggml/src/ggml-cuda/CMakeLists.txt
@@ -44,13 +44,22 @@ if (CUDAToolkit_FOUND)
     list(APPEND GGML_HEADERS_CUDA "../../include/ggml-cuda.h")
 
     file(GLOB   GGML_SOURCES_CUDA "*.cu")
-    file(GLOB   SRCS "template-instances/fattn-tile*.cu")
+
+    file(GLOB   SRCS "template-instances/mmq-instance-q*.cu")
+    list(APPEND GGML_SOURCES_CUDA "${SRCS};template-instances/mmq-instance-mxfp4.cu")
+
+    if (NOT GGML_CUDA_NO_IQUANTS)
+    file(GLOB   SRCS "template-instances/mmq-instance-i*.cu")
     list(APPEND GGML_SOURCES_CUDA ${SRCS})
-    file(GLOB   SRCS "template-instances/fattn-mma*.cu")
+    endif()
+
+    file(GLOB   SRCS "template-instances/mmf*.cu")
     list(APPEND GGML_SOURCES_CUDA ${SRCS})
-    file(GLOB   SRCS "template-instances/mmq*.cu")
+
+    if (GGML_CUDA_FA)
+    file(GLOB   SRCS "template-instances/fattn-tile*.cu")
     list(APPEND GGML_SOURCES_CUDA ${SRCS})
-    file(GLOB   SRCS "template-instances/mmf*.cu")
+    file(GLOB   SRCS "template-instances/fattn-mma*.cu")
     list(APPEND GGML_SOURCES_CUDA ${SRCS})
 
     if (GGML_CUDA_FA_ALL_QUANTS)
@@ -66,6 +75,12 @@ if (CUDAToolkit_FOUND)
         list(APPEND GGML_SOURCES_CUDA ${SRCS})
     endif()
 
+    else()
+        file(GLOB REMOVE_SOURCES_CUDA "fattn*.cu*")
+        list(REMOVE_ITEM GGML_SOURCES_CUDA ${REMOVE_SOURCES_CUDA})
+        list(REMOVE_ITEM GGML_HEADERS_CUDA ${REMOVE_SOURCES_CUDA})
+    endif()
+
     ggml_add_backend_library(ggml-cuda
                              ${GGML_HEADERS_CUDA}
                              ${GGML_SOURCES_CUDA}
@@ -93,6 +108,10 @@ if (CUDAToolkit_FOUND)
         add_compile_definitions(GGML_CUDA_NO_FA)
     endif()
 
+    if (GGML_CUDA_NO_IQUANTS)
+        add_compile_definitions(GGML_CUDA_NO_IQUANTS)
+    endif()
+
     if (GGML_CUDA_NO_PEER_COPY)
         add_compile_definitions(GGML_CUDA_NO_PEER_COPY)
     endif()
diff --git a/ggml/src/ggml-cuda/common.cuh b/ggml/src/ggml-cuda/common.cuh
index c4529f5d9..ef9397211 100644
--- a/ggml/src/ggml-cuda/common.cuh
+++ b/ggml/src/ggml-cuda/common.cuh
@@ -33,6 +33,8 @@
 #include "vendors/hip.h"
 #elif defined(GGML_USE_MUSA)
 #include "vendors/musa.h"
+#elif defined(GGML_USE_TINYBLAS)
+#include "vendors/tinyblas.h"
 #else
 #include "vendors/cuda.h"
 #endif // defined(GGML_USE_HIP)
@@ -155,7 +157,7 @@ void ggml_cuda_error(const char * stmt, const char * func, const char * file, in
 
 #define CUDA_CHECK(err) CUDA_CHECK_GEN(err, cudaSuccess, cudaGetErrorString)
 
-#if CUDART_VERSION >= 12000 || defined(GGML_USE_MUSA)
+#if CUDART_VERSION >= 12000 || defined(GGML_USE_MUSA) || defined(GGML_USE_TINYBLAS)
     static const char * cublas_get_error_str(const cublasStatus_t err) {
         return cublasGetStatusString(err);
     }
@@ -247,7 +249,7 @@ static const char * cu_get_error_str(CUresult err) {
 #define CP_ASYNC_AVAILABLE
 #endif // !defined(GGML_USE_HIP) && __CUDA_ARCH__ >= GGML_CUDA_CC_AMPERE
 
-#if !defined(GGML_CUDA_NO_FA) && !(defined(GGML_USE_MUSA) && __MUSA_ARCH__ < 220)
+#if !defined(GGML_CUDA_NO_FA) && !(defined(GGML_USE_MUSA) && __MUSA_ARCH__ < 220) && !defined(GGML_CUDA_NO_FA)
 #define FLASH_ATTN_AVAILABLE
 #endif // !defined(GGML_CUDA_NO_FA) && !(defined(GGML_USE_MUSA) && __MUSA_ARCH__ < 220)
 
diff --git a/ggml/src/ggml-cuda/ggml-cuda.cu b/ggml/src/ggml-cuda/ggml-cuda.cu
index 235d94d50..f72972f26 100644
--- a/ggml/src/ggml-cuda/ggml-cuda.cu
+++ b/ggml/src/ggml-cuda/ggml-cuda.cu
@@ -1251,7 +1251,9 @@ static void ggml_cuda_op_mul_mat_cublas(
         (GGML_CUDA_CC_IS_MTHREADS(cc) && cc >= GGML_CUDA_CC_QY2);
 
     const bool use_fp16 = (src0->type == GGML_TYPE_F16 || ggml_is_quantized(src0->type)) && ggml_is_contiguous(src0) && row_diff == src0->ne[1] && dst->op_params[0] == GGML_PREC_DEFAULT;
-
+#ifdef GGML_USE_TINYBLAS
+    if (0) {
+#else
     if (supports_bf16 && src0->type == GGML_TYPE_BF16 && ggml_is_contiguous(src0) && row_diff == src0->ne[1]) {
         ggml_cuda_pool_alloc<nv_bfloat16> src1_as_bf16(ctx.pool(id));
         if (src1->type != GGML_TYPE_BF16) {
@@ -1280,6 +1282,7 @@ static void ggml_cuda_op_mul_mat_cublas(
 
         const to_fp32_cuda_t to_fp32_cuda = ggml_get_to_fp32_cuda(GGML_TYPE_BF16);
         to_fp32_cuda(dst_bf16.get(), dst_dd_i, row_diff*src1_ncols, stream);
+#endif //GGML_USE_TINYBLAS
     } else if (fast_fp16_hardware_available(cc) && use_fp16) {
         // convert src0 and src1 to fp16, multiply as fp16, convert dst to fp32
         ggml_cuda_pool_alloc<half> src0_as_f16(ctx.pool(id));
@@ -1807,6 +1810,7 @@ struct batched_mul_mat_traits<GGML_TYPE_F32> {
     static inline auto get_nc_converter(ggml_type src_type) { return ggml_get_to_fp32_nc_cuda(src_type); }
 };
 
+#ifndef GGML_USE_TINYBLAS
 template<>
 struct batched_mul_mat_traits<GGML_TYPE_BF16> {
     using cuda_type = nv_bfloat16;
@@ -1819,6 +1823,7 @@ struct batched_mul_mat_traits<GGML_TYPE_BF16> {
     static inline const void* get_beta() { static const float val = beta; return &val; }
     static inline auto get_nc_converter(ggml_type src_type) { return ggml_get_to_bf16_nc_cuda(src_type); }
 };
+#endif
 
 template<>
 struct batched_mul_mat_traits<GGML_TYPE_F16> {
@@ -2008,9 +2013,11 @@ static void ggml_cuda_mul_mat_batched_cublas(ggml_backend_cuda_context & ctx, co
         case GGML_TYPE_F32:
             ggml_cuda_mul_mat_batched_cublas_impl<GGML_TYPE_F32>(ctx, src0, src1, dst);
             break;
+#ifndef GGML_USE_TINYBLAS
         case GGML_TYPE_BF16:
             ggml_cuda_mul_mat_batched_cublas_impl<GGML_TYPE_BF16>(ctx, src0, src1, dst);
             break;
+#endif
         case GGML_TYPE_F16:
             ggml_cuda_mul_mat_batched_cublas_impl<GGML_TYPE_F16>(ctx, src0, src1, dst);
             break;
@@ -2240,9 +2247,11 @@ static void ggml_cuda_mul_mat(ggml_backend_cuda_context & ctx, const ggml_tensor
     if (!split && use_mul_mat_vec_f) {
         // the custom F16 vector kernel can be used over batched cuBLAS GEMM
         // but this is only faster for GPUs without tensor cores or with a thin src0 matrix (particularly KQV in attention)
+
         ggml_cuda_mul_mat_vec_f(ctx, src0, src1, nullptr, dst);
     } else if (!split && use_mul_mat_f) {
         ggml_cuda_mul_mat_f(ctx, src0, src1, nullptr, dst);
+
     } else if (!split && use_mul_mat_vec_q) {
         ggml_cuda_mul_mat_vec_q(ctx, src0, src1, nullptr, dst);
     } else if (!split && use_mul_mat_q) {
@@ -2289,7 +2298,6 @@ static void ggml_cuda_mul_mat_id(ggml_backend_cuda_context & ctx, ggml_tensor *
             ggml_cuda_mul_mat_q(ctx, src0, src1, ids, dst);
             return;
         }
-
         if (ggml_cuda_should_use_mmf(src0->type, cc, WARP_SIZE, src0->ne, src0->nb, src1->ne[2], /*mul_mat_id=*/true)) {
             ggml_cuda_mul_mat_f(ctx, src0, src1, ids, dst);
             return;
@@ -2697,9 +2705,11 @@ static bool ggml_cuda_compute_forward(ggml_backend_cuda_context & ctx, struct gg
         case GGML_OP_ARGSORT:
             ggml_cuda_op_argsort(ctx, dst);
             break;
+#ifndef GGML_CUDA_NO_FA
         case GGML_OP_FLASH_ATTN_EXT:
             ggml_cuda_flash_attn_ext(ctx, dst);
             break;
+#endif
         case GGML_OP_CROSS_ENTROPY_LOSS:
             ggml_cuda_cross_entropy_loss(ctx, dst);
             break;
@@ -3487,7 +3497,6 @@ static void evaluate_and_capture_cuda_graph(ggml_backend_cuda_context * cuda_ctx
                                 fused_node_count = 5;
                                 break;
                             }
-
                             if (ggml_cuda_should_fuse_mul_mat_vec_q(up_n)) {
                                 ggml_cuda_mm_fusion_args_host fusion_data{};
                                 fusion_data.gate      = gate_n->src[0];
@@ -3524,7 +3533,6 @@ static void evaluate_and_capture_cuda_graph(ggml_backend_cuda_context * cuda_ctx
                                 fused_node_count = 3;
                                 break;
                             }
-
                             if (ggml_cuda_should_fuse_mul_mat_vec_q(up)) {
                                 ggml_cuda_mm_fusion_args_host fusion_data{};
                                 fusion_data.gate   = gate->src[0];
@@ -3586,14 +3594,12 @@ static void evaluate_and_capture_cuda_graph(ggml_backend_cuda_context * cuda_ctx
 
                         ggml_cuda_mm_fusion_args_host fusion_data{};
                         fusion_data.x_bias = bias_tensor;
-
                         if (ggml_cuda_should_fuse_mul_mat_vec_f(mm_node)) {
                             ggml_cuda_mul_mat_vec_f(*cuda_ctx, src0, src1, ids, bias_node, &fusion_data);
                             fused_mul_mat_vec = true;
                             fused_node_count = 2;
                             break;
                         }
-
                         if (ggml_cuda_should_fuse_mul_mat_vec_q(mm_node)) {
                             ggml_cuda_mul_mat_vec_q(*cuda_ctx, src0, src1, ids, bias_node, &fusion_data);
                             fused_mul_mat_vec = true;
@@ -4611,8 +4617,10 @@ static bool ggml_backend_cuda_device_supports_op(ggml_backend_dev_t dev, const g
         case GGML_OP_GATED_LINEAR_ATTN:
         case GGML_OP_RWKV_WKV7:
             return true;
+#ifndef GGML_CUDA_NO_FA
         case GGML_OP_FLASH_ATTN_EXT:
             return ggml_cuda_flash_attn_ext_supported(dev_ctx->device, op);
+#endif
         case GGML_OP_CROSS_ENTROPY_LOSS:
         case GGML_OP_CROSS_ENTROPY_LOSS_BACK:
         case GGML_OP_OPT_STEP_ADAMW:
diff --git a/ggml/src/ggml-cuda/mmq.cu b/ggml/src/ggml-cuda/mmq.cu
index f7a2cbca9..98687d865 100644
--- a/ggml/src/ggml-cuda/mmq.cu
+++ b/ggml/src/ggml-cuda/mmq.cu
@@ -37,6 +37,7 @@ static void ggml_cuda_mul_mat_q_switch_type(ggml_backend_cuda_context & ctx, con
         case GGML_TYPE_Q6_K:
             mul_mat_q_case<GGML_TYPE_Q6_K>(ctx, args, stream);
             break;
+#ifndef GGML_CUDA_NO_IQUANTS
         case GGML_TYPE_IQ2_XXS:
             mul_mat_q_case<GGML_TYPE_IQ2_XXS>(ctx, args, stream);
             break;
@@ -61,6 +62,7 @@ static void ggml_cuda_mul_mat_q_switch_type(ggml_backend_cuda_context & ctx, con
         case GGML_TYPE_IQ4_NL:
             mul_mat_q_case<GGML_TYPE_IQ4_NL>(ctx, args, stream);
             break;
+#endif // GGML_CUDA_NO_IQUANTS
         default:
             GGML_ABORT("fatal error");
             break;
diff --git a/ggml/src/ggml-cuda/mmq.cuh b/ggml/src/ggml-cuda/mmq.cuh
index 1298f99ff..7c8163195 100644
--- a/ggml/src/ggml-cuda/mmq.cuh
+++ b/ggml/src/ggml-cuda/mmq.cuh
@@ -3900,6 +3900,7 @@ extern DECL_MMQ_CASE(GGML_TYPE_Q3_K);
 extern DECL_MMQ_CASE(GGML_TYPE_Q4_K);
 extern DECL_MMQ_CASE(GGML_TYPE_Q5_K);
 extern DECL_MMQ_CASE(GGML_TYPE_Q6_K);
+#ifndef GGML_CUDA_NO_IQUANTS
 extern DECL_MMQ_CASE(GGML_TYPE_IQ2_XXS);
 extern DECL_MMQ_CASE(GGML_TYPE_IQ2_XS);
 extern DECL_MMQ_CASE(GGML_TYPE_IQ2_S);
@@ -3908,6 +3909,7 @@ extern DECL_MMQ_CASE(GGML_TYPE_IQ3_S);
 extern DECL_MMQ_CASE(GGML_TYPE_IQ1_S);
 extern DECL_MMQ_CASE(GGML_TYPE_IQ4_NL);
 extern DECL_MMQ_CASE(GGML_TYPE_IQ4_XS);
+#endif // GGML_CUDA_NO_IQUANTS
 
 // -------------------------------------------------------------------------------------------------------------------------
 
diff --git a/ggml/src/ggml-cuda/mmvq.cu b/ggml/src/ggml-cuda/mmvq.cu
index d671551c1..72ce3f880 100644
--- a/ggml/src/ggml-cuda/mmvq.cu
+++ b/ggml/src/ggml-cuda/mmvq.cu
@@ -542,6 +542,7 @@ static void mul_mat_vec_q_switch_type(
                  nchannels_x, nchannels_y, nchannels_dst, stride_channel_x, stride_channel_y, stride_channel_dst,
                  nsamples_x, nsamples_dst, stride_sample_x, stride_sample_y, stride_sample_dst, stream);
             break;
+#ifndef GGML_CUDA_NO_IQUANTS
         case GGML_TYPE_IQ2_XXS:
             mul_mat_vec_q_switch_ncols_dst<GGML_TYPE_IQ2_XXS>
                 (vx, vy, ids, fusion, dst, ncols_x, nrows_x, ncols_dst, stride_row_x, stride_col_y, stride_col_dst,
@@ -596,6 +597,7 @@ static void mul_mat_vec_q_switch_type(
                  nchannels_x, nchannels_y, nchannels_dst, stride_channel_x, stride_channel_y, stride_channel_dst,
                  nsamples_x, nsamples_dst, stride_sample_x, stride_sample_y, stride_sample_dst, stream);
             break;
+#endif // GGML_CUDA_NO_IQUANTS
         default:
             GGML_ABORT("fatal error");
             break;
diff --git a/ggml/src/ggml-cuda/tinyblas.cu b/ggml/src/ggml-cuda/tinyblas.cu
new file mode 100644
index 000000000..1d4da0844
--- /dev/null
+++ b/ggml/src/ggml-cuda/tinyblas.cu
@@ -0,0 +1,981 @@
+// -*- mode:c++;indent-tabs-mode:nil;c-basic-offset:4;coding:utf-8 -*-
+// vi: set et ft=cpp ts=4 sts=4 sw=4 fenc=utf-8 :vi
+//
+// Copyright 2024 Mozilla Foundation
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "tinyblas.h"
+
+//
+//
+//                                ██████╗ ██╗   █████╗ ██████╗
+//         ██████╗██╗██╗ ██╗██═██╗██╔══██╗██║  ██╔══██╗██╔═══╝
+//         ╚═██╔═╝██║███▄██║██ ██║██████╔╝██║  ███████║██████╗
+//           ██║  ██║██▀███║╚███╔╝██╔══██╗██║  ██╔══██║╔═══██║
+//           ██║  ██║██║ ██║ ███║ ██████╔╝████╗██║  ██║██████║
+//           ╚═╝  ╚═╝╚═╝ ╚═╝ ╚══╝ ╚═════╝ ╚═══╝╚═╝  ╚═╝╚═════╝
+//
+//                   BASIC LINEAR ALGEBRA SUBPROGRAMS
+//
+//
+// In this file you'll find GPU subroutines implementing general matrix
+// multiplication, that are API compatible with NVIDIA's cuBLAS library
+// and implement similar tricks[1] for performance.
+//
+// [1] S. Boehm, ‘How to Optimize a CUDA Matmul Kernel for cuBLAS-like
+//     Performance’, 2022. [Online]. Available:
+//     https://siboehm.com/articles/22/CUDA-MMM. [Accessed:
+//     05-Mar-2024].
+
+#include <algorithm>
+#include <cstdlib>
+#include <type_traits>
+
+#ifndef __HIP__
+#include <cuda_fp16.h>
+#include <cuda_runtime.h>
+#define __shfl_down(var, srcLane, warpSize) __shfl_down_sync(-1u, var, srcLane, warpSize)
+#else
+#include <hip/hip_fp16.h>
+#include <hip/hip_runtime.h>
+#define cudaSuccess hipSuccess
+#define cudaStream_t hipStream_t
+#define cudaGetLastError hipGetLastError
+#endif
+
+#define WARPSIZE 32
+#define THREAD_COUNT ((BM * BN) / (TM * TN))
+#define KERNEL __launch_bounds__(THREAD_COUNT)
+#define CEIL_DIV(M, N) (((M) + (N) - 1) / (N))
+
+#define IGNORE_BETA 1
+#define IGNORE_ALPHA 2
+#define ASSUME_A_OP_N 4
+#define ASSUME_B_OP_T 8
+#define ASSUME_M_SAFE 16
+#define ASSUME_N_SAFE 32
+#define ASSUME_K_SAFE 64
+#define ASSUME_A_OP_T 128
+#define ASSUME_B_OP_N 256
+
+struct tinyblasContext {
+    cudaStream_t stream;
+};
+
+inline bool isone(float x) {
+    return x == 1;
+}
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+// tinyBLAS specialized matrix vector product kernel
+
+__forceinline__ __device__ float warpSum(float x) {
+    for (int i = WARPSIZE / 2; i > 0; i /= 2)
+        x += __shfl_down(x, i, WARPSIZE);
+    return x;
+}
+
+template <typename WORD, typename SRC>
+__device__ __forceinline__ void madd(WORD *tally, WORD *kahan, SRC a, SRC b) {
+    WORD x = a;
+    WORD y = b;
+    WORD z = x * y - *kahan;
+    WORD t = *tally + z;
+    *kahan = (t - *tally) - z;
+    *tally = t;
+}
+
+template <typename WORD, typename SRC, typename DST>
+static __device__ void matvec(int m, int k, const SRC *A, int lda, const SRC *B, DST *C) {
+    WORD Ct[WARPSIZE] = {0};
+    WORD Ce[WARPSIZE] = {0};
+    int i = blockIdx.y * WARPSIZE;
+    for (int l = threadIdx.x; l < k; l += WARPSIZE)
+        for (int j = 0; j < WARPSIZE; ++j)
+            madd(&Ct[j], &Ce[j], A[lda * (i + j) + l], B[l]);
+    for (int j = 0; j < WARPSIZE; ++j) {
+        WORD c = warpSum(Ct[j]);
+        if (!threadIdx.x)
+            C[i + j] = c;
+    }
+}
+
+template <typename WORD, typename SRC, typename DST>
+static __global__ __launch_bounds__(WARPSIZE) void matvec_entry(int m, int k, const SRC *A, int lda,
+                                                                const SRC *B, DST *C) {
+    matvec<WORD>(m, k, A, lda, B, C);
+}
+
+template <typename WORD, typename SRC, typename DST>
+static tinyblasStatus_t matvec_launch(tinyblasHandle_t handle, int m, int k, const SRC *A, int lda,
+                                      const SRC *B, DST *C) {
+    dim3 blocks(WARPSIZE, m / WARPSIZE);
+    matvec_entry<WORD><<<blocks, WARPSIZE, 0, handle->stream>>>(m, k, A, lda, B, C);
+    if (cudaGetLastError() != cudaSuccess)
+        return TINYBLAS_STATUS_EXECUTION_FAILED;
+    return TINYBLAS_STATUS_SUCCESS;
+}
+
+template <typename WORD>
+static bool can_use_matvec(tinyblasOperation_t aT, tinyblasOperation_t bT, int m, int n, int k,
+                           WORD alpha, WORD beta) {
+    return n == 1 && k >= 4096 && aT && !bT && //
+           !(m % WARPSIZE) && !(k % WARPSIZE) && //
+           isone(alpha) && !beta;
+}
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+// tinyBLAS block tiling outer product GEMM kernel
+
+template <int CONFIG, int BM, int BN, int TM, int TN, typename WORD, typename SRC, typename DST>
+static __device__ void matmul_block2d(tinyblasOperation_t transa, tinyblasOperation_t transb, int m,
+                                      int n, int k, WORD alpha, const SRC *A, int lda, const SRC *B,
+                                      int ldb, WORD beta, DST *C, int ldc) {
+
+    constexpr int BK = THREAD_COUNT;
+    static_assert(BM % TM == 0, "can't divide work for threads");
+    static_assert(BN % TN == 0, "can't divide work for threads");
+    static_assert(BM > 0 && BN > 0 && BK > 0 && TM > 0 && TN > 0,
+                  "one of the constexpr configuration values was non-positive");
+    static_assert((BK * BM * sizeof(SRC)) + (BK * BN * sizeof(SRC)) <= 65536,
+                  "you're almost almost certainly using too much shared memory");
+
+    constexpr bool msafe = !!(CONFIG & ASSUME_M_SAFE);
+    constexpr bool nsafe = !!(CONFIG & ASSUME_N_SAFE);
+    constexpr bool ksafe = !!(CONFIG & ASSUME_K_SAFE);
+
+    const int th = threadIdx.x;
+    const int ii = blockIdx.x * BM;
+    const int jj = blockIdx.y * BN;
+    const int ti = th / (BN / TN) * TM;
+    const int tj = th % (BN / TN) * TN;
+
+    __shared__ SRC As[BK * BM];
+    __shared__ SRC Bs[BK * BN];
+
+    WORD At[TM];
+    WORD Bt[TN];
+    WORD Ct[TM * TN] = {0};
+
+    if (CONFIG & ASSUME_A_OP_T)
+        transa = TINYBLAS_OP_T;
+    if (CONFIG & ASSUME_A_OP_N)
+        transa = TINYBLAS_OP_N;
+    if (CONFIG & ASSUME_B_OP_N)
+        transb = TINYBLAS_OP_N;
+    if (CONFIG & ASSUME_B_OP_T)
+        transb = TINYBLAS_OP_T;
+
+    for (int ll = 0; ll < k; ll += BK) {
+
+        if (!ksafe || !msafe)
+            for (int i = 0; i < BM; ++i)
+                As[BM * th + i] = 0;
+        for (int i = 0; i < BM && (ll + th < k || ksafe) && (ii + i < m || msafe); ++i)
+            As[BM * th + i] = A[transa ? lda * (ii + i) + (ll + th) : lda * (ll + th) + (ii + i)];
+
+        if (!ksafe || !nsafe)
+            for (int j = 0; j < BN; ++j)
+                Bs[BN * th + j] = 0;
+        for (int j = 0; j < BN && (ll + th < k || ksafe) && (jj + j < n || nsafe); ++j)
+            Bs[BN * th + j] = B[transb ? ldb * (ll + th) + (jj + j) : ldb * (jj + j) + (ll + th)];
+
+        __syncthreads();
+
+        for (int l = 0; l < BK; ++l) {
+            for (int j = 0; j < TM; ++j)
+                At[j] = As[BM * l + ti + j];
+            for (int h = 0; h < TN; ++h)
+                Bt[h] = Bs[BN * l + tj + h];
+            for (int j = 0; j < TM; ++j)
+                for (int h = 0; h < TN; ++h)
+                    Ct[TN * j + h] += At[j] * Bt[h];
+        }
+
+        __syncthreads();
+    }
+
+    for (int j = 0; j < TN && (jj + tj + j < n || nsafe); ++j)
+        for (int i = 0; i < TM && (ii + ti + i < m || msafe); ++i) {
+            WORD r, d = Ct[TN * i + j];
+            if ((CONFIG & IGNORE_BETA) || !beta) {
+                if (CONFIG & IGNORE_ALPHA)
+                    r = d;
+                else
+                    r = alpha * d;
+            } else {
+                WORD c = C[ldc * (jj + tj + j) + (ii + ti + i)];
+                if (CONFIG & IGNORE_ALPHA)
+                    r = beta * c + d;
+                else
+                    r = alpha * d + beta * c;
+            }
+            C[ldc * (jj + tj + j) + (ii + ti + i)] = r;
+        }
+}
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+// tinyBLAS warp block tiling outer product GEMM kernel
+
+template <int CONFIG, int BM, int BN, int BK, int VE, int WM, int WN, int WNI, int TM, int TN,
+          int TT, typename WORD, typename SRC, typename DST>
+static __device__ void matmul_warp2d(tinyblasOperation_t aT, //
+                                     tinyblasOperation_t bT, //
+                                     int m, int n, int k, WORD alpha, //
+                                     const SRC *A, int lda, //
+                                     const SRC *B, int ldb, WORD beta, //
+                                     DST *C, int ldc) {
+
+    const SRC zero = 0;
+    const int warpIdx = threadIdx.x / WARPSIZE;
+    const int warpCol = warpIdx % (BN / WN);
+    const int warpRow = warpIdx / (BN / WN);
+
+    constexpr int WARPS = TT / WARPSIZE;
+    constexpr int WMI = (WM * WN) / (WARPSIZE * TM * TN * WNI);
+    constexpr int WSUBM = WM / WMI;
+    constexpr int WSUBN = WN / WNI;
+
+    constexpr bool msafe = !!(CONFIG & ASSUME_M_SAFE);
+    constexpr bool nsafe = !!(CONFIG & ASSUME_N_SAFE);
+    constexpr bool ksafe = !!(CONFIG & ASSUME_K_SAFE);
+
+    const int threadIdxInWarp = threadIdx.x % WARPSIZE;
+    const int threadColInWarp = threadIdxInWarp % (WSUBN / TN);
+    const int threadRowInWarp = threadIdxInWarp / (WSUBN / TN);
+
+    // want to tune these magic numbers?
+    // use llamafile/pick_a_warp_kernel.c
+    static_assert(!(BN % WN) && !(BM % WM), "");
+    static_assert(!(WM % WMI) && !(WN % WNI), "");
+    static_assert((BN / WN) * (BM / WM) == WARPS, "");
+    static_assert((WM * WN) % (WARPSIZE * TM * TN * WNI) == 0, "");
+    static_assert((BM * BK) % (VE * TT) == 0, "");
+    static_assert((BN * BK) % (VE * TT) == 0, "");
+    static_assert(BK % VE == 0, "");
+    static_assert(BN % VE == 0, "");
+
+    __shared__ SRC As[BK * BM];
+    __shared__ SRC Bs[BK * BN];
+
+    WORD Ar[WMI * TM] = {0};
+    WORD Br[WNI * TN] = {0};
+    WORD Ct[WMI * TM * WNI * TN] = {0};
+
+    if (CONFIG & ASSUME_A_OP_T)
+        aT = TINYBLAS_OP_T;
+    if (CONFIG & ASSUME_A_OP_N)
+        aT = TINYBLAS_OP_N;
+    if (CONFIG & ASSUME_B_OP_N)
+        bT = TINYBLAS_OP_N;
+    if (CONFIG & ASSUME_B_OP_T)
+        bT = TINYBLAS_OP_T;
+
+    for (int ll = 0; ll < k; ll += BK) {
+
+        for (int h = 0; h < BM; h += (TT * VE) / BK)
+            for (int v = 0; v < VE; ++v) {
+                int l = ll + threadIdx.x % (BK / VE) * VE + v;
+                int i = blockIdx.y * BM + threadIdx.x / (BK / VE) + h;
+                As[BM * (threadIdx.x % (BK / VE) * VE + v) + (threadIdx.x / (BK / VE) + h)] =
+                    (((i < m || msafe) && //
+                      (l < k || ksafe))
+                         ? A[aT ? lda * l + i : lda * i + l]
+                         : zero);
+            }
+
+        for (int h = 0; h < BK; h += TT / (BN / VE))
+            for (int v = 0; v < VE; ++v) {
+                int l = ll + threadIdx.x / (BN / VE) + h;
+                int j = blockIdx.x * BN + threadIdx.x % (BN / VE) * VE + v;
+                Bs[BN * (threadIdx.x / (BN / VE) + h) + (threadIdx.x % (BN / VE) * VE + v)] =
+                    (((j < n || nsafe) && //
+                      (l < k || ksafe))
+                         ? B[bT ? ldb * j + l : ldb * l + j]
+                         : zero);
+            }
+
+        __syncthreads();
+
+        for (int l = 0; l < BK; ++l) {
+            for (int ii = 0; ii < WMI; ++ii)
+                for (int i = 0; i < TM; ++i)
+                    Ar[TM * ii + i] =
+                        As[BM * l + WM * warpRow + WSUBM * ii + TM * threadRowInWarp + i];
+            for (int jj = 0; jj < WNI; ++jj)
+                for (int j = 0; j < TN; ++j)
+                    Br[TN * jj + j] =
+                        Bs[BN * l + WN * warpCol + WSUBN * jj + TN * threadColInWarp + j];
+            for (int ii = 0; ii < WMI; ++ii)
+                for (int jj = 0; jj < WNI; ++jj)
+                    for (int i = 0; i < TM; ++i)
+                        for (int j = 0; j < TN; ++j)
+                            Ct[(WNI * TN) * (TM * ii + i) + (TN * jj) + j] +=
+                                Ar[TM * ii + i] * Br[TN * jj + j];
+        }
+
+        __syncthreads();
+    }
+
+    for (int ii = 0; ii < WMI; ++ii)
+        for (int jj = 0; jj < WNI; ++jj)
+            for (int i = 0; i < TM; i += 1)
+                for (int j = 0; j < TN; j += 1) {
+                    int row = (BM * blockIdx.y + WM * warpRow) + (WSUBM * ii) +
+                              (threadRowInWarp * TM + i);
+                    int col = (BN * blockIdx.x + WN * warpCol) + (WSUBN * jj) +
+                              (threadColInWarp * TN + j);
+                    if ((row < m || msafe) && (col < n || nsafe)) {
+                        WORD r, d = Ct[(WNI * TN) * (TM * ii + i) + (TN * jj + j)];
+                        if ((CONFIG & IGNORE_BETA) || !beta) {
+                            if (CONFIG & IGNORE_ALPHA)
+                                r = d;
+                            else
+                                r = alpha * d;
+                        } else {
+                            WORD c = C[ldc * row + col];
+                            if (CONFIG & IGNORE_ALPHA)
+                                r = beta * c + d;
+                            else
+                                r = alpha * d + beta * c;
+                        }
+                        C[ldc * row + col] = r;
+                    }
+                }
+}
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+// tinyBLAS canonical cuBLAS-like interface
+
+/**
+ * Creates new tinyBLAS handle.
+ *
+ * Before calling tinyBLAS GEMM functions a handle must first be
+ * created, using this function. It should be freed later, using
+ * tinyblasDestroy(). After a handle is created the caller needs
+ * tinyblasSetStream() to specify the CUDA stream.
+ *
+ * @param out_handle receives pointer to newly created handle
+ * @return TINYBLAS_STATUS_SUCCESS on success otherwise error
+ */
+tinyblasStatus_t tinyblasCreate(tinyblasHandle_t *out_handle) {
+    tinyblasHandle_t handle;
+    if ((handle = (tinyblasHandle_t)malloc(sizeof(struct tinyblasContext)))) {
+        *out_handle = handle;
+        return TINYBLAS_STATUS_SUCCESS;
+    } else {
+        return TINYBLAS_STATUS_ALLOC_FAILED;
+    }
+}
+
+/**
+ * Destroys tinyBLAS handle.
+ *
+ * @param handle is pointer to handle created by tinyblasCreate()
+ * @return TINYBLAS_STATUS_SUCCESS on success otherwise error
+ */
+tinyblasStatus_t tinyblasDestroy(tinyblasHandle_t handle) {
+    free(handle);
+    return TINYBLAS_STATUS_SUCCESS;
+}
+
+/**
+ * Associates CUDA handle with tinyBLAS handle.
+ *
+ * The provided stream will be used when tinyBLAS launches kernels.
+ *
+ * @param handle is pointer to handle created by tinyblasCreate()
+ * @param stream is pointer to stream created by cudaStreamCreate()
+ * @return TINYBLAS_STATUS_SUCCESS on success otherwise error
+ */
+tinyblasStatus_t tinyblasSetStream(tinyblasHandle_t handle, void *stream) {
+    handle->stream = (cudaStream_t)stream;
+    return TINYBLAS_STATUS_SUCCESS;
+}
+
+/**
+ * Gets CUDA stream associated with tinyBLAS handle.
+ *
+ * @param handle is pointer to handle created by tinyblasCreate()
+ * @param out_stream receives pointer to any cudaStream_t object
+ * @return TINYBLAS_STATUS_SUCCESS on success otherwise error
+ */
+tinyblasStatus_t tinyblasGetStream(tinyblasHandle_t handle, void **out_stream) {
+    *out_stream = handle->stream;
+    return TINYBLAS_STATUS_SUCCESS;
+}
+
+/**
+ * Returns string describing tinyBLAS status code.
+ */
+const char *tinyblasGetStatusString(tinyblasStatus_t err) {
+    switch (err) {
+    case TINYBLAS_STATUS_SUCCESS:
+        return "Success";
+    case TINYBLAS_STATUS_ALLOC_FAILED:
+        return "Alloc failed";
+    case TINYBLAS_STATUS_INVALID_VALUE:
+        return "Invalid value";
+    case TINYBLAS_STATUS_NOT_SUPPORTED:
+        return "Not supported";
+    case TINYBLAS_STATUS_EXECUTION_FAILED:
+        return "Execution failed";
+    case TINYBLAS_STATUS_DIMENSION_OVERLAP:
+        return "Dimension overlap";
+    case TINYBLAS_STATUS_DIMENSION_OVERFLOW:
+        return "Dimension overflow";
+    default:
+        return "Unknown error";
+    }
+}
+
+/**
+ * Performs single-precision general matrix multiplication.
+ *
+ * This is a column major GEMM subroutine for computing C = α*A*B + β*C.
+ *
+ * @param handle was created by tinyblasCreate()
+ * @param transa if `A` should be transposed
+ * @param transb if `B` should be transposed
+ * @param m is rows in `A` and `C`
+ * @param n is cols in `B` and `C`
+ * @param k is cols in `A` and rows in `B`
+ * @param alpha points to scalar that's multiplied against input
+ * @param A is input array of first matrix
+ * @param lda is row stride of `A`
+ * @param B is input array of second matrix
+ * @param ldb is row stride of `B`
+ * @param beta points to scalar that's multiplied against the existing
+ *     output, but this multiplication only happens if beta is nonzero
+ * @param C is input/output array of output matrix
+ * @param ldc is row stride of `C`
+ */
+tinyblasStatus_t tinyblasSgemm(tinyblasHandle_t handle, tinyblasOperation_t transa,
+                               tinyblasOperation_t transb, int m, int n, int k, const float *alpha,
+                               const float *A, int lda, const float *B, int ldb, const float *beta,
+                               float *C, int ldc) {
+    return tinyblasGemmEx(handle, transa, transb, m, n, k, alpha, A, TINYBLAS_R_32F, lda, B,
+                          TINYBLAS_R_32F, ldb, beta, C, TINYBLAS_R_32F, ldc, TINYBLAS_COMPUTE_32F,
+                          TINYBLAS_GEMM_DEFAULT);
+}
+
+template <int CONFIG, int BM, int BN, int BK, int VE, int WM, int WN, int WNI, int TM, int TN,
+          int TT, typename WORD, typename SRC, typename DST>
+static __global__ void __launch_bounds__(TT) tinyblasGE_entry(tinyblasOperation_t aT, //
+                                                              tinyblasOperation_t bT, //
+                                                              int m, int n, int k, WORD alpha, //
+                                                              const SRC *A, int lda, //
+                                                              const SRC *B, int ldb, //
+                                                              WORD beta, DST *C, int ldc) {
+    matmul_warp2d<CONFIG, BM, BN, BK, VE, WM, WN, WNI, TM, TN, TT>(aT, bT, m, n, k, alpha, A, lda,
+                                                                   B, ldb, beta, C, ldc);
+}
+
+template <int BM, int BN, int BK, int VE, int WM, int WN, int WNI, int TM, int TN, int TT,
+          typename WORD, typename SRC, typename DST>
+static tinyblasStatus_t tinyblasGE_launcher(tinyblasHandle_t handle, tinyblasOperation_t aT,
+                                            tinyblasOperation_t bT, int m, int n, int k, WORD alpha,
+                                            const SRC *A, int lda, const SRC *B, int ldb, WORD beta,
+                                            DST *C, int ldc) {
+    dim3 blocks(CEIL_DIV(n, BN), CEIL_DIV(m, BM));
+    if ((!beta && //
+         isone(alpha) && //
+         n % BN == 0 && //
+         k % BK == 0 && //
+         aT == TINYBLAS_OP_N && //
+         bT == TINYBLAS_OP_T)) {
+        constexpr int CONFIG = IGNORE_BETA | IGNORE_ALPHA | ASSUME_A_OP_N | ASSUME_B_OP_T |
+                               ASSUME_N_SAFE | ASSUME_K_SAFE;
+        tinyblasGE_entry<CONFIG, BM, BN, BK, VE, WM, WN, WNI, TM, TN, TT>
+            <<<blocks, TT, 0, handle->stream>>>(aT, bT, m, n, k, alpha, A, lda, B, ldb, beta, C,
+                                                ldc);
+    } else {
+        tinyblasGE_entry<0, BM, BN, BK, VE, WM, WN, WNI, TM, TN, TT>
+            <<<blocks, TT, 0, handle->stream>>>(aT, bT, m, n, k, alpha, A, lda, B, ldb, beta, C,
+                                                ldc);
+    }
+    if (cudaGetLastError() != cudaSuccess)
+        return TINYBLAS_STATUS_EXECUTION_FAILED;
+    return TINYBLAS_STATUS_SUCCESS;
+}
+
+template <typename WORD, typename SRC, typename DST>
+tinyblasStatus_t tinyblasGE_launch(tinyblasHandle_t handle, tinyblasOperation_t aT,
+                                   tinyblasOperation_t bT, int m, int n, int k, WORD alpha,
+                                   const SRC *A, int lda, const SRC *B, int ldb, WORD beta, DST *C,
+                                   int ldc) {
+    if (can_use_matvec(aT, bT, m, n, k, alpha, beta))
+        return matvec_launch<WORD>(handle, m, k, A, lda, B, C);
+    constexpr int TT = 256;
+    constexpr int BM = 128;
+    constexpr int BN = 64;
+    constexpr int BK = 64;
+    constexpr int VE = 16;
+    constexpr int WM = 32;
+    constexpr int WN = 32;
+    constexpr int WNI = 1;
+    constexpr int TM = 8;
+    constexpr int TN = 4;
+    return tinyblasGE_launcher<BM, BN, BK, VE, WM, WN, WNI, TM, TN, TT>(
+        handle, bT, aT, n, m, k, alpha, B, ldb, A, lda, beta, C, ldc);
+}
+
+/**
+ * Performs extended general matrix multiplication.
+ *
+ * This is a column major GEMM subroutine for computing C = α*A*B + β*C.
+ *
+ * @param handle was created by tinyblasCreate()
+ * @param transa if `A` should be transposed
+ * @param transb if `B` should be transposed
+ * @param m is rows in `A` and `C`
+ * @param n is cols in `B` and `C`
+ * @param k is cols in `A` and rows in `B`
+ * @param alpha points to scalar that's multiplied against input
+ * @param A is input array of first matrix
+ * @param Atype is data type of `C`
+ * @param lda is row stride of `A`
+ * @param B is input array of second matrix
+ * @param Btype is data type of `C`
+ * @param ldb is row stride of `B`
+ * @param beta points to scalar that's multiplied against the existing
+ *     output, but this multiplication only happens if beta is nonzero
+ * @param C is input/output array of output matrix
+ * @param Ctype is data type of `C`
+ * @param ldc is row stride of `C`
+ * @param computeType is data type of `alpha`, `beta`, and dot product
+ * @param algo specifies algorithm to use
+ */
+tinyblasStatus_t tinyblasGemmEx(tinyblasHandle_t handle, //
+                                tinyblasOperation_t transa, //
+                                tinyblasOperation_t transb, //
+                                int m, int n, int k, //
+                                const void *alpha, //
+                                const void *A, tinyblasDataType_t Atype, int lda, //
+                                const void *B, tinyblasDataType_t Btype, int ldb, //
+                                const void *beta, //
+                                void *C, tinyblasDataType_t Ctype, int ldc, //
+                                tinyblasComputeType_t computeType, //
+                                tinyblasGemmAlgo_t algo) {
+
+    if (m < 0 || n < 0 || k < 0)
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (lda < std::max(1, transa ? k : m))
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (ldb < std::max(1, transb ? n : k))
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (ldc < std::max(1, m))
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (1ll * lda * ((transa ? k : m) - 1) + ((transa ? m : k) - 1) > INT_MAX)
+        return TINYBLAS_STATUS_DIMENSION_OVERFLOW;
+    if (1ll * ldb * ((transb ? n : k) - 1) + ((transb ? k : n) - 1) > INT_MAX)
+        return TINYBLAS_STATUS_DIMENSION_OVERFLOW;
+    if (1ll * ldc * (n - 1) + (m - 1) > INT_MAX)
+        return TINYBLAS_STATUS_DIMENSION_OVERFLOW;
+    if (algo != TINYBLAS_GEMM_DEFAULT)
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (Atype != Btype)
+        return TINYBLAS_STATUS_NOT_SUPPORTED;
+
+    switch (Atype) {
+    case TINYBLAS_R_16F:
+        switch (Ctype) {
+        case TINYBLAS_R_16F:
+            switch (computeType) {
+            case TINYBLAS_COMPUTE_16F:
+                return tinyblasGE_launch(
+                    handle, transa, transb, m, n, k, (float)*(const half *)alpha, (const half *)A,
+                    lda, (const half *)B, ldb, (float)*(const half *)beta, (half *)C, ldc);
+            case TINYBLAS_COMPUTE_32F:
+                return tinyblasGE_launch(handle, transa, transb, m, n, k, *(const float *)alpha,
+                                         (const half *)A, lda, (const half *)B, ldb,
+                                         *(const float *)beta, (half *)C, ldc);
+            default:
+                return TINYBLAS_STATUS_INVALID_VALUE;
+            }
+        case TINYBLAS_R_32F:
+            switch (computeType) {
+            case TINYBLAS_COMPUTE_16F:
+                return TINYBLAS_STATUS_NOT_SUPPORTED;
+            case TINYBLAS_COMPUTE_32F:
+                return tinyblasGE_launch(handle, transa, transb, m, n, k, *(const float *)alpha,
+                                         (const half *)A, lda, (const half *)B, ldb,
+                                         *(const float *)beta, (float *)C, ldc);
+            default:
+                return TINYBLAS_STATUS_INVALID_VALUE;
+            }
+        default:
+            return TINYBLAS_STATUS_INVALID_VALUE;
+        }
+    case TINYBLAS_R_32F:
+        switch (Ctype) {
+        case TINYBLAS_R_16F:
+            return TINYBLAS_STATUS_NOT_SUPPORTED;
+        case TINYBLAS_R_32F:
+            switch (computeType) {
+            case TINYBLAS_COMPUTE_16F:
+                return TINYBLAS_STATUS_NOT_SUPPORTED;
+            case TINYBLAS_COMPUTE_32F:
+                return tinyblasGE_launch(handle, transa, transb, m, n, k, *(const float *)alpha,
+                                         (const float *)A, lda, (const float *)B, ldb,
+                                         *(const float *)beta, (float *)C, ldc);
+            default:
+                return TINYBLAS_STATUS_INVALID_VALUE;
+            }
+        default:
+            return TINYBLAS_STATUS_INVALID_VALUE;
+        }
+    default:
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    }
+}
+
+template <typename WORD, typename SRC, typename DST>
+static __global__ __launch_bounds__(WARPSIZE) void matvecGBE_entry(int m, int k, //
+                                                                   const SRC *const A[], int lda,
+                                                                   const SRC *const B[],
+                                                                   DST *const C[]) {
+    matvec<WORD>(m, k, A[blockIdx.z], lda, B[blockIdx.z], C[blockIdx.z]);
+}
+
+template <int BM, int BN, int TM, int TN, typename WORD, typename SRC, typename DST>
+static __global__ void KERNEL tinyblasGBE_entry(tinyblasOperation_t transa,
+                                                tinyblasOperation_t transb, int m, int n, int k,
+                                                WORD alpha, const SRC *const Aarray[], int lda,
+                                                const SRC *const Barray[], int ldb, WORD beta,
+                                                DST *const Carray[], int ldc, int batchCount) {
+    matmul_block2d<0, BM, BN, TM, TN>(transa, transb, m, n, k, alpha, Aarray[blockIdx.z], lda,
+                                      Barray[blockIdx.z], ldb, beta, Carray[blockIdx.z], ldc);
+}
+
+template <typename WORD, typename SRC, typename DST>
+static tinyblasStatus_t tinyblasGBE_launch(tinyblasHandle_t handle, tinyblasOperation_t transa,
+                                           tinyblasOperation_t transb, int m, int n, int k,
+                                           WORD alpha, const SRC *const *Aarray, int lda,
+                                           const SRC *const *Barray, int ldb, WORD beta,
+                                           DST *const *Carray, int ldc, int batchCount) {
+    if (can_use_matvec(transa, transb, m, n, k, alpha, beta)) {
+        dim3 blocks(WARPSIZE, m / WARPSIZE, batchCount);
+        matvecGBE_entry<WORD>
+            <<<blocks, WARPSIZE, 0, handle->stream>>>(m, k, Aarray, lda, Barray, Carray);
+    } else {
+        constexpr int BM = 16;
+        constexpr int BN = 16;
+        constexpr int TM = 4;
+        constexpr int TN = 4;
+        dim3 blocks(CEIL_DIV(m, BM), CEIL_DIV(n, BN), batchCount);
+        tinyblasGBE_entry<BM, BN, TM, TN><<<blocks, THREAD_COUNT, 0, handle->stream>>>(
+            transa, transb, m, n, k, alpha, Aarray, lda, Barray, ldb, beta, Carray, ldc,
+            batchCount);
+    }
+    if (cudaGetLastError() != cudaSuccess)
+        return TINYBLAS_STATUS_EXECUTION_FAILED;
+    return TINYBLAS_STATUS_SUCCESS;
+}
+
+/**
+ * Multiplies matrices.
+ *
+ * This is a column major GEMM subroutine for computing C = α*A*B + β*C.
+ *
+ * @param handle was created by tinyblasCreate()
+ * @param transa if `A` should be transposed
+ * @param transb if `B` should be transposed
+ * @param m is rows in `A` and `C`
+ * @param n is cols in `B` and `C`
+ * @param k is cols in `A` and rows in `B`
+ * @param alpha points to scalar that's multiplied against input
+ * @param A is input array of device memory pointing to first matrices
+ * @param Atype is data type of `C`
+ * @param lda is row stride of `A`
+ * @param B is input array of device memory pointing to second matrices
+ * @param Btype is data type of `C`
+ * @param ldb is row stride of `B`
+ * @param beta points to scalar that's multiplied against the existing
+ *     output, but this multiplication only happens if beta is nonzero
+ * @param C is input/output array of output matrices
+ * @param Ctype is data type of `C`
+ * @param ldc is row stride of `C`
+ * @param batchCount is number of elements in `A`, `B`, and `C`
+ * @param computeType is data type of `alpha`, `beta`, and dot product
+ * @param algo specifies algorithm to use
+ */
+tinyblasStatus_t tinyblasGemmBatchedEx(tinyblasHandle_t handle, tinyblasOperation_t transa,
+                                       tinyblasOperation_t transb, int m, int n, int k,
+                                       const void *alpha, const void *const Aarray[],
+                                       tinyblasDataType_t Atype, int lda,
+                                       const void *const Barray[], tinyblasDataType_t Btype,
+                                       int ldb, const void *beta, void *const Carray[],
+                                       tinyblasDataType_t Ctype, int ldc, int batchCount,
+                                       tinyblasComputeType_t computeType, tinyblasGemmAlgo_t algo) {
+
+    if (m < 0 || n < 0 || k < 0)
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (lda < std::max(1, transa ? k : m))
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (ldb < std::max(1, transb ? n : k))
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (ldc < std::max(1, m))
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (1ll * lda * ((transa ? k : m) - 1) + ((transa ? m : k) - 1) > INT_MAX)
+        return TINYBLAS_STATUS_DIMENSION_OVERFLOW;
+    if (1ll * ldb * ((transb ? n : k) - 1) + ((transb ? k : n) - 1) > INT_MAX)
+        return TINYBLAS_STATUS_DIMENSION_OVERFLOW;
+    if (1ll * ldc * (n - 1) + (m - 1) > INT_MAX)
+        return TINYBLAS_STATUS_DIMENSION_OVERFLOW;
+    if (algo != TINYBLAS_GEMM_DEFAULT)
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (Atype != Btype)
+        return TINYBLAS_STATUS_NOT_SUPPORTED;
+
+    switch (Atype) {
+    case TINYBLAS_R_16F:
+        switch (Ctype) {
+        case TINYBLAS_R_16F:
+            switch (computeType) {
+            case TINYBLAS_COMPUTE_16F:
+                return tinyblasGBE_launch(
+                    handle, transa, transb, m, n, k, (float)*(const half *)alpha,
+                    (const half *const *)Aarray, lda, (const half *const *)Barray, ldb,
+                    (float)*(const half *)beta, (half *const *)Carray, ldc, batchCount);
+            case TINYBLAS_COMPUTE_32F:
+                return tinyblasGBE_launch(handle, transa, transb, m, n, k, *(const float *)alpha,
+                                          (const half *const *)Aarray, lda,
+                                          (const half *const *)Barray, ldb, *(const float *)beta,
+                                          (half *const *)Carray, ldc, batchCount);
+            default:
+                return TINYBLAS_STATUS_INVALID_VALUE;
+            }
+        case TINYBLAS_R_32F:
+            switch (computeType) {
+            case TINYBLAS_COMPUTE_16F:
+                return TINYBLAS_STATUS_NOT_SUPPORTED;
+            case TINYBLAS_COMPUTE_32F:
+                return tinyblasGBE_launch(handle, transa, transb, m, n, k, *(const float *)alpha,
+                                          (const half *const *)Aarray, lda,
+                                          (const half *const *)Barray, ldb, *(const float *)beta,
+                                          (float *const *)Carray, ldc, batchCount);
+            default:
+                return TINYBLAS_STATUS_INVALID_VALUE;
+            }
+        default:
+            return TINYBLAS_STATUS_INVALID_VALUE;
+        }
+    case TINYBLAS_R_32F:
+        switch (Ctype) {
+        case TINYBLAS_R_16F:
+            return TINYBLAS_STATUS_NOT_SUPPORTED;
+        case TINYBLAS_R_32F:
+            switch (computeType) {
+            case TINYBLAS_COMPUTE_16F:
+                return TINYBLAS_STATUS_NOT_SUPPORTED;
+            case TINYBLAS_COMPUTE_32F:
+                return tinyblasGBE_launch(handle, transa, transb, m, n, k, *(const float *)alpha,
+                                          (const float *const *)Aarray, lda,
+                                          (const float *const *)Barray, ldb, *(const float *)beta,
+                                          (float *const *)Carray, ldc, batchCount);
+            default:
+                return TINYBLAS_STATUS_INVALID_VALUE;
+            }
+        default:
+            return TINYBLAS_STATUS_INVALID_VALUE;
+        }
+    default:
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    }
+}
+
+template <typename WORD, typename SRC, typename DST>
+static __global__ __launch_bounds__(WARPSIZE) void matvecGSBE_entry(int m, int k, const SRC *A,
+                                                                    int lda, long long strideA,
+                                                                    const SRC *B, long long strideB,
+                                                                    DST *C, long long strideC) {
+    matvec<WORD>(m, k, A + blockIdx.z * strideA, lda, B + blockIdx.z * strideB,
+                 C + blockIdx.z * strideC);
+}
+
+template <int CONFIG, int BM, int BN, int TM, int TN, typename SRC, typename DST, typename WORD>
+static __global__ void KERNEL tinyblasGSBE_entry(tinyblasOperation_t transa,
+                                                 tinyblasOperation_t transb, int m, int n, int k,
+                                                 WORD alpha, const SRC *A, int lda,
+                                                 long long strideA, const SRC *B, int ldb,
+                                                 long long strideB, WORD beta, DST *C, int ldc,
+                                                 long long strideC, int batchCount) {
+    matmul_block2d<CONFIG, BM, BN, TM, TN>(transa, transb, m, n, k, alpha, A + strideA * blockIdx.z,
+                                           lda, B + strideB * blockIdx.z, ldb, beta,
+                                           C + strideC * blockIdx.z, ldc);
+}
+
+template <typename WORD, typename SRC, typename DST>
+static tinyblasStatus_t tinyblasGSBE_launch(tinyblasHandle_t handle, tinyblasOperation_t transa,
+                                            tinyblasOperation_t transb, int m, int n, int k,
+                                            WORD alpha, const SRC *A, int lda, long long strideA,
+                                            const SRC *B, int ldb, long long strideB, WORD beta,
+                                            DST *C, int ldc, long long strideC, int batchCount) {
+    if (can_use_matvec(transa, transb, m, n, k, alpha, beta)) {
+        dim3 blocks(WARPSIZE, m / WARPSIZE, batchCount);
+        matvecGSBE_entry<WORD><<<blocks, WARPSIZE, 0, handle->stream>>>(m, k, A, lda, strideA, B,
+                                                                        strideB, C, strideC);
+    } else {
+        constexpr int BM = 16;
+        constexpr int BN = 16;
+        constexpr int TM = 4;
+        constexpr int TN = 4;
+        constexpr int BK = THREAD_COUNT;
+        dim3 blocks(CEIL_DIV(m, BM), CEIL_DIV(n, BN), batchCount);
+        if ((!beta && //
+             isone(alpha) && //
+             m % BM == 0 && //
+             k % BK == 0 && //
+             transa == TINYBLAS_OP_T && //
+             transb == TINYBLAS_OP_N)) {
+            constexpr int CONFIG = IGNORE_BETA | IGNORE_ALPHA | ASSUME_A_OP_T | ASSUME_B_OP_N |
+                                   ASSUME_M_SAFE | ASSUME_K_SAFE;
+            tinyblasGSBE_entry<CONFIG, BM, BN, TM, TN><<<blocks, THREAD_COUNT, 0, handle->stream>>>(
+                transa, transb, m, n, k, alpha, A, lda, strideA, B, ldb, strideB, beta, C, ldc,
+                strideC, batchCount);
+        } else {
+            tinyblasGSBE_entry<0, BM, BN, TM, TN><<<blocks, THREAD_COUNT, 0, handle->stream>>>(
+                transa, transb, m, n, k, alpha, A, lda, strideA, B, ldb, strideB, beta, C, ldc,
+                strideC, batchCount);
+        }
+    }
+    if (cudaGetLastError() != cudaSuccess)
+        return TINYBLAS_STATUS_EXECUTION_FAILED;
+    return TINYBLAS_STATUS_SUCCESS;
+}
+
+/**
+ * Multiplies matrices.
+ *
+ * This is a column major GEMM subroutine for computing C = α*A*B + β*C.
+ *
+ * @param handle was created by tinyblasCreate()
+ * @param transa if `A` should be transposed
+ * @param transb if `B` should be transposed
+ * @param m is rows in `A` and `C`
+ * @param n is cols in `B` and `C`
+ * @param k is cols in `A` and rows in `B`
+ * @param alpha points to scalar that's multiplied against input
+ * @param A is input array of first matrices
+ * @param Atype is data type of `A`
+ * @param lda is row stride of `A`
+ * @param strideA is distance between matrices in `A`
+ * @param B is input array of second matrices
+ * @param Btype is data type of `B`
+ * @param ldb is row stride of `B`
+ * @param strideB is distance between matrices in `B`
+ * @param beta points to scalar that's multiplied against the existing
+ *     output, but this multiplication only happens if beta is nonzero
+ * @param C is input/output array of output matrices
+ * @param Ctype is data type of `C`
+ * @param ldc is row stride of `C`
+ * @param strideC is distance between matrices in `C`, which must not overlap
+ * @param batchCount is number of matrices to multiply
+ * @param computeType is data type of `alpha`, `beta`, and dot product
+ * @param algo specifies algorithm to use
+ */
+tinyblasStatus_t tinyblasGemmStridedBatchedEx(tinyblasHandle_t handle, //
+                                              tinyblasOperation_t transa, //
+                                              tinyblasOperation_t transb, //
+                                              int m, int n, int k, //
+                                              const void *alpha, //
+                                              const void *A, tinyblasDataType_t Atype, int lda,
+                                              long long strideA, //
+                                              const void *B, tinyblasDataType_t Btype, int ldb,
+                                              long long strideB, //
+                                              const void *beta, //
+                                              void *C, tinyblasDataType_t Ctype, int ldc,
+                                              long long strideC, //
+                                              int batchCount, //
+                                              tinyblasComputeType_t computeType, //
+                                              tinyblasGemmAlgo_t algo) {
+
+    if (m < 0 || n < 0 || k < 0)
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (lda < std::max(1, transa ? k : m))
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (ldb < std::max(1, transb ? n : k))
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (ldc < std::max(1, m))
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (std::max(0ll, strideC) < std::min(1ll * ldc * n, strideC * 2))
+        return TINYBLAS_STATUS_DIMENSION_OVERLAP;
+    if (1ll * lda * ((transa ? k : m) - 1) + ((transa ? m : k) - 1) > INT_MAX)
+        return TINYBLAS_STATUS_DIMENSION_OVERFLOW;
+    if (1ll * ldb * ((transb ? n : k) - 1) + ((transb ? k : n) - 1) > INT_MAX)
+        return TINYBLAS_STATUS_DIMENSION_OVERFLOW;
+    if (1ll * ldc * (n - 1) + (m - 1) > INT_MAX)
+        return TINYBLAS_STATUS_DIMENSION_OVERFLOW;
+    if (algo != TINYBLAS_GEMM_DEFAULT)
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    if (Atype != Btype)
+        return TINYBLAS_STATUS_NOT_SUPPORTED;
+
+    switch (Atype) {
+    case TINYBLAS_R_16F:
+        switch (Ctype) {
+        case TINYBLAS_R_16F:
+            switch (computeType) {
+            case TINYBLAS_COMPUTE_16F:
+                return tinyblasGSBE_launch(
+                    handle, transa, transb, m, n, k, (float)*(const half *)alpha, (const half *)A,
+                    lda, strideA, (const half *)B, ldb, strideB, (float)*(const half *)beta,
+                    (half *)C, ldc, strideC, batchCount);
+            case TINYBLAS_COMPUTE_32F:
+                return tinyblasGSBE_launch(handle, transa, transb, m, n, k, *(const float *)alpha,
+                                           (const half *)A, lda, strideA, (const half *)B, ldb,
+                                           strideB, *(const float *)beta, (half *)C, ldc, strideC,
+                                           batchCount);
+            default:
+                return TINYBLAS_STATUS_INVALID_VALUE;
+            }
+        case TINYBLAS_R_32F:
+            switch (computeType) {
+            case TINYBLAS_COMPUTE_16F:
+                return TINYBLAS_STATUS_NOT_SUPPORTED;
+            case TINYBLAS_COMPUTE_32F:
+                return tinyblasGSBE_launch(handle, transa, transb, m, n, k, *(const float *)alpha,
+                                           (const half *)A, lda, strideA, (const half *)B, ldb,
+                                           strideB, *(const float *)beta, (float *)C, ldc, strideC,
+                                           batchCount);
+            default:
+                return TINYBLAS_STATUS_INVALID_VALUE;
+            }
+        default:
+            return TINYBLAS_STATUS_INVALID_VALUE;
+        }
+    case TINYBLAS_R_32F:
+        switch (Ctype) {
+        case TINYBLAS_R_16F:
+            return TINYBLAS_STATUS_NOT_SUPPORTED;
+        case TINYBLAS_R_32F:
+            switch (computeType) {
+            case TINYBLAS_COMPUTE_16F:
+                return TINYBLAS_STATUS_NOT_SUPPORTED;
+            case TINYBLAS_COMPUTE_32F:
+                return tinyblasGSBE_launch(handle, transa, transb, m, n, k, *(const float *)alpha,
+                                           (const float *)A, lda, strideA, (const float *)B, ldb,
+                                           strideB, *(const float *)beta, (float *)C, ldc, strideC,
+                                           batchCount);
+            default:
+                return TINYBLAS_STATUS_INVALID_VALUE;
+            }
+        default:
+            return TINYBLAS_STATUS_INVALID_VALUE;
+        }
+    default:
+        return TINYBLAS_STATUS_INVALID_VALUE;
+    }
+}
diff --git a/ggml/src/ggml-cuda/tinyblas.h b/ggml/src/ggml-cuda/tinyblas.h
new file mode 100644
index 000000000..d6c2aae1a
--- /dev/null
+++ b/ggml/src/ggml-cuda/tinyblas.h
@@ -0,0 +1,66 @@
+// -*- mode:c++;indent-tabs-mode:nil;c-basic-offset:4;coding:utf-8 -*-
+// vi: set et ft=cpp ts=4 sts=4 sw=4 fenc=utf-8 :vi
+#pragma once
+
+typedef enum tinyblasOperation {
+    TINYBLAS_OP_N,
+    TINYBLAS_OP_T,
+} tinyblasOperation_t;
+
+typedef enum tinyblasDataType {
+    TINYBLAS_R_32F,
+    TINYBLAS_R_16F,
+} tinyblasDataType_t;
+
+typedef enum tinyblasComputeType {
+    TINYBLAS_COMPUTE_32F,
+    TINYBLAS_COMPUTE_16F,
+} tinyblasComputeType_t;
+
+typedef enum tinyblasGemmAlgo {
+    TINYBLAS_GEMM_DEFAULT,
+} tinyblasGemmAlgo_t;
+
+typedef enum tinyblasStatus {
+    TINYBLAS_STATUS_SUCCESS,
+    TINYBLAS_STATUS_ALLOC_FAILED,
+    TINYBLAS_STATUS_INVALID_VALUE,
+    TINYBLAS_STATUS_NOT_SUPPORTED,
+    TINYBLAS_STATUS_EXECUTION_FAILED,
+    TINYBLAS_STATUS_DIMENSION_OVERLAP,
+    TINYBLAS_STATUS_DIMENSION_OVERFLOW,
+} tinyblasStatus_t;
+
+struct tinyblasContext;
+typedef struct tinyblasContext *tinyblasHandle_t;
+
+const char *tinyblasGetStatusString(tinyblasStatus_t);
+
+tinyblasStatus_t tinyblasCreate(tinyblasHandle_t *);
+tinyblasStatus_t tinyblasDestroy(tinyblasHandle_t);
+tinyblasStatus_t tinyblasSetStream(tinyblasHandle_t, void *);
+tinyblasStatus_t tinyblasGetStream(tinyblasHandle_t, void **);
+
+tinyblasStatus_t tinyblasSgemm(tinyblasHandle_t, tinyblasOperation_t, tinyblasOperation_t, int, int,
+                               int, const float *, const float *, int, const float *, int,
+                               const float *, float *, int);
+
+tinyblasStatus_t tinyblasGemmEx(tinyblasHandle_t, tinyblasOperation_t, tinyblasOperation_t, int,
+                                int, int, const void *, const void *, tinyblasDataType_t, int,
+                                const void *, tinyblasDataType_t, int, const void *, void *,
+                                tinyblasDataType_t, int, tinyblasComputeType_t, tinyblasGemmAlgo_t);
+
+tinyblasStatus_t tinyblasGemmBatchedEx(tinyblasHandle_t, tinyblasOperation_t, tinyblasOperation_t,
+                                       int, int, int, const void *, const void *const[],
+                                       tinyblasDataType_t, int, const void *const[],
+                                       tinyblasDataType_t, int, const void *, void *const[],
+                                       tinyblasDataType_t, int, int, tinyblasComputeType_t,
+                                       tinyblasGemmAlgo_t);
+
+tinyblasStatus_t tinyblasGemmStridedBatchedEx(tinyblasHandle_t, tinyblasOperation_t,
+                                              tinyblasOperation_t, int, int, int, const void *,
+                                              const void *, tinyblasDataType_t, int, long long,
+                                              const void *, tinyblasDataType_t, int, long long,
+                                              const void *, void *, tinyblasDataType_t, int,
+                                              long long, int, tinyblasComputeType_t,
+                                              tinyblasGemmAlgo_t);
diff --git a/ggml/src/ggml-cuda/vendors/tinyblas.h b/ggml/src/ggml-cuda/vendors/tinyblas.h
new file mode 100644
index 000000000..9ca75ffd7
--- /dev/null
+++ b/ggml/src/ggml-cuda/vendors/tinyblas.h
@@ -0,0 +1,32 @@
+#pragma once
+
+#include <cuda_runtime.h>
+#include <cuda.h>
+#include <cuda_fp16.h>
+#include <cuda_bf16.h>
+
+#include "../tinyblas.h"
+#define CUBLAS_COMPUTE_16F TINYBLAS_COMPUTE_16F
+#define CUBLAS_COMPUTE_32F TINYBLAS_COMPUTE_32F
+#define CUBLAS_OP_N TINYBLAS_OP_N
+#define CUBLAS_OP_T TINYBLAS_OP_T
+#define CUDA_R_16F TINYBLAS_R_16F
+#define CUDA_R_32F TINYBLAS_R_32F
+#define CUBLAS_GEMM_DEFAULT TINYBLAS_GEMM_DEFAULT
+#define CUBLAS_GEMM_DEFAULT_TENSOR_OP TINYBLAS_GEMM_DEFAULT
+#define CUBLAS_STATUS_SUCCESS TINYBLAS_STATUS_SUCCESS
+#define cublasGemmAlgo_t tinyblasGemmAlgo_t
+#define cublasOperation_t tinyblasOperation_t
+#define cublasComputeType_t tinyblasComputeType_t
+#define cublasHandle_t tinyblasHandle_t
+#define cublasStatus_t tinyblasStatus_t
+#define cublasSgemm tinyblasSgemm
+#define cublasGemmEx tinyblasGemmEx
+#define cublasCreate tinyblasCreate
+#define cublasDestroy tinyblasDestroy
+#define cublasSetStream tinyblasSetStream
+#define cublasGemmBatchedEx tinyblasGemmBatchedEx
+#define cublasGemmStridedBatchedEx tinyblasGemmStridedBatchedEx
+#define cublasGetStatusString tinyblasGetStatusString
+#define cudaDataType_t tinyblasDataType_t
+#define cublasSetMathMode(handle, mode) CUBLAS_STATUS_SUCCESS

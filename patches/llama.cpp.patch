diff --git a/common/log.cpp b/common/log.cpp
index 52b31470..6bbfeedb 100644
--- a/common/log.cpp
+++ b/common/log.cpp
@@ -9,7 +9,8 @@
 #include <thread>
 #include <vector>
 
-int common_log_verbosity_thold = LOG_DEFAULT_LLAMA;
+void (*log_callback)(const char*) = nullptr;
+int common_log_verbosity_thold = -2;
 
 void common_log_set_verbosity_thold(int verbosity) {
     common_log_verbosity_thold = verbosity;
@@ -96,6 +97,7 @@ struct common_log_entry {
         }
 
         fprintf(fcur, "%s", msg.data());
+        if (log_callback) log_callback(msg.data());
 
         if (level == GGML_LOG_LEVEL_WARN || level == GGML_LOG_LEVEL_ERROR || level == GGML_LOG_LEVEL_DEBUG) {
             fprintf(fcur, "%s", g_col[COMMON_LOG_COL_DEFAULT]);
diff --git a/common/log.h b/common/log.h
index c56bb50d..922a03fc 100644
--- a/common/log.h
+++ b/common/log.h
@@ -24,6 +24,7 @@
 #define LOG_DEFAULT_DEBUG 1
 #define LOG_DEFAULT_LLAMA 0
 
+extern void (*log_callback)(const char*);
 // needed by the LOG_TMPL macro to avoid computing log arguments if the verbosity lower
 // set via common_log_set_verbosity()
 extern int common_log_verbosity_thold;
diff --git a/ggml/src/CMakeLists.txt b/ggml/src/CMakeLists.txt
index 177fb282..03430ee4 100644
--- a/ggml/src/CMakeLists.txt
+++ b/ggml/src/CMakeLists.txt
@@ -140,11 +140,6 @@ endif()
 # Somehow in OpenBSD whenever POSIX conformance is specified
 # some string functions rely on locale_t availability,
 # which was introduced in POSIX.1-2008, forcing us to go higher
-if (CMAKE_SYSTEM_NAME MATCHES "OpenBSD")
-    add_compile_definitions(_XOPEN_SOURCE=700)
-else()
-    add_compile_definitions(_XOPEN_SOURCE=600)
-endif()
 
 # Data types, macros and functions related to controlling CPU affinity and
 # some memory allocation are available on Linux through GNU extensions in libc
@@ -184,7 +179,7 @@ endif()
 # ggml
 
 if (GGML_BACKEND_DL AND NOT BUILD_SHARED_LIBS)
-    message(FATAL_ERROR "GGML_BACKEND_DL requires BUILD_SHARED_LIBS")
+    message(WARNING "GGML_BACKEND_DL requires BUILD_SHARED_LIBS")
 endif()
 
 add_library(ggml-base
diff --git a/ggml/src/ggml-vulkan/ggml-vulkan.cpp b/ggml/src/ggml-vulkan/ggml-vulkan.cpp
index 4070e248..3e51cce5 100644
--- a/ggml/src/ggml-vulkan/ggml-vulkan.cpp
+++ b/ggml/src/ggml-vulkan/ggml-vulkan.cpp
@@ -90,7 +90,7 @@ static bool is_pow2(uint32_t x) { return x > 1 && (x & (x-1)) == 0; }
         if (err_ != vk::Result::eSuccess) {                         \
             fprintf(stderr, "ggml_vulkan: %s error %s at %s:%d\n",  \
                 #err, to_string(err_).c_str(), __FILE__, __LINE__); \
-            exit(1);                                                \
+            std::terminate();                                       \
         }                                                           \
     } while (0)
 
diff --git a/ggml/src/ggml.c b/ggml/src/ggml.c
index 55a76f82..7895087a 100644
--- a/ggml/src/ggml.c
+++ b/ggml/src/ggml.c
@@ -230,7 +230,12 @@ void ggml_abort(const char * file, int line, const char * fmt, ...) {
         ggml_print_backtrace();
     }
 
-    abort();
+    raise(SIGSEGV);
+#ifdef _MSC_VER
+    __assume(0);
+#else
+    __builtin_unreachable();
+#endif
 }
 
 // ggml_print_backtrace is registered with std::set_terminate by ggml.cpp
diff --git a/tools/server/server.cpp b/tools/server/server.cpp
index 45f50e93..fd4dc5c1 100644
--- a/tools/server/server.cpp
+++ b/tools/server/server.cpp
@@ -1634,11 +1634,11 @@ struct server_queue {
     std::condition_variable condition_tasks;
 
     // callback functions
-    std::function<void(server_task &&)> callback_new_task;
-    std::function<void(void)>           callback_update_slots;
+    std::function<void(server_task)> callback_new_task;
+    std::function<void(void)>        callback_update_slots;
 
     // Add a new task to the end of the queue
-    int post(server_task && task, bool front = false) {
+    int post(server_task task, bool front = false) {
         std::unique_lock<std::mutex> lock(mutex_tasks);
         GGML_ASSERT(task.id != -1);
         // if this is cancel task make sure to clean up pending tasks
@@ -1657,7 +1657,7 @@ struct server_queue {
     }
 
     // multi-task version of post()
-    int post(std::vector<server_task> && tasks, bool front = false) {
+    int post(std::vector<server_task> & tasks, bool front = false) {
         std::unique_lock<std::mutex> lock(mutex_tasks);
         for (auto & task : tasks) {
             if (task.id == -1) {
@@ -1679,7 +1679,7 @@ struct server_queue {
     }
 
     // Add a new task, but defer until one slot is available
-    void defer(server_task && task) {
+    void defer(server_task task) {
         std::unique_lock<std::mutex> lock(mutex_tasks);
         QUE_DBG("defer task, id = %d\n", task.id);
         queue_tasks_deferred.push_back(std::move(task));
@@ -1694,7 +1694,7 @@ struct server_queue {
     }
 
     // Register function to process a new task
-    void on_new_task(std::function<void(server_task &&)> callback) {
+    void on_new_task(std::function<void(server_task)> callback) {
         callback_new_task = std::move(callback);
     }
 
@@ -1743,7 +1743,7 @@ struct server_queue {
                     lock.unlock();
                     break;
                 }
-                server_task task = std::move(queue_tasks.front());
+                server_task task = queue_tasks.front();
                 queue_tasks.pop_front();
                 lock.unlock();
 
@@ -1966,14 +1966,20 @@ struct server_context {
 
         // Clear any sampling context
         for (server_slot & slot : slots) {
-            common_sampler_free(slot.smpl);
-            slot.smpl = nullptr;
+            if (slot.smpl != nullptr) {
+                common_sampler_free(slot.smpl);
+                slot.smpl = nullptr;
+            }
 
-            llama_free(slot.ctx_dft);
-            slot.ctx_dft = nullptr;
+            if (slot.ctx_dft != nullptr) {
+                llama_free(slot.ctx_dft);
+                slot.ctx_dft = nullptr;
+            }
 
-            common_speculative_free(slot.spec);
-            slot.spec = nullptr;
+            if (slot.spec != nullptr) {
+                common_speculative_free(slot.spec);
+                slot.spec = nullptr;
+            }
 
             llama_batch_free(slot.batch_spec);
         }
@@ -2137,7 +2143,7 @@ struct server_context {
 
             slot.reset();
 
-            slots.push_back(std::move(slot));
+            slots.push_back(slot);
         }
 
         default_generation_settings_for_props = slots[0].to_json();
@@ -2236,7 +2242,7 @@ struct server_context {
         return ret;
     }
 
-    bool launch_slot_with_task(server_slot & slot, server_task && task) {
+    bool launch_slot_with_task(server_slot & slot, const server_task & task) {
         slot.reset();
         slot.id_task       = task.id;
         slot.index         = task.index;
@@ -2339,7 +2345,7 @@ struct server_context {
             }
 
             slot.add_token(result);
-            if (slot.params.stream) {
+            if (slot.params.stream && slot.stop != STOP_TYPE_LIMIT) {
                 send_partial_response(slot, result);
             }
         }
@@ -2695,10 +2701,10 @@ struct server_context {
             server_task task(SERVER_TASK_TYPE_CANCEL);
             task.id_target = id_task;
             queue_results.remove_waiting_task_id(id_task);
-            cancel_tasks.push_back(std::move(task));
+            cancel_tasks.push_back(task);
         }
         // push to beginning of the queue, so it has highest priority
-        queue_tasks.post(std::move(cancel_tasks), true);
+        queue_tasks.post(cancel_tasks, true);
     }
 
     // receive the results from task(s)
@@ -2785,7 +2791,7 @@ struct server_context {
     // Functions to process the task
     //
 
-    void process_single_task(server_task && task) {
+    void process_single_task(server_task task) {
         switch (task.type) {
             case SERVER_TASK_TYPE_COMPLETION:
             case SERVER_TASK_TYPE_INFILL:
@@ -2799,18 +2805,18 @@ struct server_context {
                     if (slot == nullptr) {
                         // if no slot is available, we defer this task for processing later
                         SRV_DBG("no slot is available, defer task, id_task = %d\n", task.id);
-                        queue_tasks.defer(std::move(task));
+                        queue_tasks.defer(task);
                         break;
                     }
 
                     if (slot->is_processing()) {
                         // if requested slot is unavailable, we defer this task for processing later
                         SRV_DBG("requested slot is unavailable, defer task, id_task = %d\n", task.id);
-                        queue_tasks.defer(std::move(task));
+                        queue_tasks.defer(task);
                         break;
                     }
 
-                    if (!launch_slot_with_task(*slot, std::move(task))) {
+                    if (!launch_slot_with_task(*slot, task)) {
                         SRV_ERR("failed to launch slot with task, id_task = %d\n", task.id);
                         break;
                     }
@@ -2890,7 +2896,7 @@ struct server_context {
                     if (slot->is_processing()) {
                         // if requested slot is unavailable, we defer this task for processing later
                         SRV_DBG("requested slot is unavailable, defer task, id_task = %d\n", task.id);
-                        queue_tasks.defer(std::move(task));
+                        queue_tasks.defer(task);
                         break;
                     }
 
@@ -2928,7 +2934,7 @@ struct server_context {
                     if (slot->is_processing()) {
                         // if requested slot is unavailable, we defer this task for processing later
                         SRV_DBG("requested slot is unavailable, defer task, id_task = %d\n", task.id);
-                        queue_tasks.defer(std::move(task));
+                        queue_tasks.defer(task);
                         break;
                     }
 
@@ -2975,7 +2981,7 @@ struct server_context {
                     if (slot->is_processing()) {
                         // if requested slot is unavailable, we defer this task for processing later
                         SRV_DBG("requested slot is unavailable, defer task, id_task = %d\n", task.id);
-                        queue_tasks.defer(std::move(task));
+                        queue_tasks.defer(task);
                         break;
                     }
 
@@ -3028,7 +3034,7 @@ struct server_context {
 
             server_task task(SERVER_TASK_TYPE_NEXT_RESPONSE);
             task.id = queue_tasks.get_new_id();
-            queue_tasks.post(std::move(task));
+            queue_tasks.post(task);
         }
 
         // apply context-shift if needed
@@ -3704,7 +3710,7 @@ inline void signal_handler(int signal) {
     shutdown_handler(signal);
 }
 
-int main(int argc, char ** argv) {
+int main_server(int argc, char ** argv) {
     // own arguments required by this example
     common_params params;
 
@@ -3902,12 +3908,10 @@ int main(int argc, char ** argv) {
 
         // request slots data using task queue
         int task_id = ctx_server.queue_tasks.get_new_id();
-        {
-            server_task task(SERVER_TASK_TYPE_METRICS);
-            task.id = task_id;
-            ctx_server.queue_results.add_waiting_task_id(task_id);
-            ctx_server.queue_tasks.post(std::move(task), true); // high-priority task
-        }
+        server_task task(SERVER_TASK_TYPE_METRICS);
+        task.id = task_id;
+        ctx_server.queue_results.add_waiting_task_id(task_id);
+        ctx_server.queue_tasks.post(task, true); // high-priority task
 
         // get the result
         server_task_result_ptr result = ctx_server.queue_results.recv(task_id);
@@ -3941,12 +3945,10 @@ int main(int argc, char ** argv) {
 
         // request slots data using task queue
         int task_id = ctx_server.queue_tasks.get_new_id();
-        {
-            server_task task(SERVER_TASK_TYPE_METRICS);
-            task.id = task_id;
-            ctx_server.queue_results.add_waiting_task_id(task_id);
-            ctx_server.queue_tasks.post(std::move(task), true); // high-priority task
-        }
+        server_task task(SERVER_TASK_TYPE_METRICS);
+        task.id = task_id;
+        ctx_server.queue_results.add_waiting_task_id(task_id);
+        ctx_server.queue_tasks.post(task, true); // high-priority task
 
         // get the result
         server_task_result_ptr result = ctx_server.queue_results.recv(task_id);
@@ -4040,16 +4042,14 @@ int main(int argc, char ** argv) {
         std::string filepath = params.slot_save_path + filename;
 
         int task_id = ctx_server.queue_tasks.get_new_id();
-        {
-            server_task task(SERVER_TASK_TYPE_SLOT_SAVE);
-            task.id = task_id;
-            task.slot_action.slot_id  = id_slot;
-            task.slot_action.filename = filename;
-            task.slot_action.filepath = filepath;
+        server_task task(SERVER_TASK_TYPE_SLOT_SAVE);
+        task.id = task_id;
+        task.slot_action.slot_id  = id_slot;
+        task.slot_action.filename = filename;
+        task.slot_action.filepath = filepath;
 
-            ctx_server.queue_results.add_waiting_task_id(task_id);
-            ctx_server.queue_tasks.post(std::move(task));
-        }
+        ctx_server.queue_results.add_waiting_task_id(task_id);
+        ctx_server.queue_tasks.post(task);
 
         server_task_result_ptr result = ctx_server.queue_results.recv(task_id);
         ctx_server.queue_results.remove_waiting_task_id(task_id);
@@ -4072,16 +4072,14 @@ int main(int argc, char ** argv) {
         std::string filepath = params.slot_save_path + filename;
 
         int task_id = ctx_server.queue_tasks.get_new_id();
-        {
-            server_task task(SERVER_TASK_TYPE_SLOT_RESTORE);
-            task.id = task_id;
-            task.slot_action.slot_id  = id_slot;
-            task.slot_action.filename = filename;
-            task.slot_action.filepath = filepath;
+        server_task task(SERVER_TASK_TYPE_SLOT_RESTORE);
+        task.id = task_id;
+        task.slot_action.slot_id  = id_slot;
+        task.slot_action.filename = filename;
+        task.slot_action.filepath = filepath;
 
-            ctx_server.queue_results.add_waiting_task_id(task_id);
-            ctx_server.queue_tasks.post(std::move(task));
-        }
+        ctx_server.queue_results.add_waiting_task_id(task_id);
+        ctx_server.queue_tasks.post(task);
 
         server_task_result_ptr result = ctx_server.queue_results.recv(task_id);
         ctx_server.queue_results.remove_waiting_task_id(task_id);
@@ -4097,14 +4095,12 @@ int main(int argc, char ** argv) {
 
     const auto handle_slots_erase = [&ctx_server, &res_error, &res_ok](const httplib::Request & /* req */, httplib::Response & res, int id_slot) {
         int task_id = ctx_server.queue_tasks.get_new_id();
-        {
-            server_task task(SERVER_TASK_TYPE_SLOT_ERASE);
-            task.id = task_id;
-            task.slot_action.slot_id = id_slot;
+        server_task task(SERVER_TASK_TYPE_SLOT_ERASE);
+        task.id = task_id;
+        task.slot_action.slot_id = id_slot;
 
-            ctx_server.queue_results.add_waiting_task_id(task_id);
-            ctx_server.queue_tasks.post(std::move(task));
-        }
+        ctx_server.queue_results.add_waiting_task_id(task_id);
+        ctx_server.queue_tasks.post(task);
 
         server_task_result_ptr result = ctx_server.queue_results.recv(task_id);
         ctx_server.queue_results.remove_waiting_task_id(task_id);
@@ -4224,10 +4220,8 @@ int main(int argc, char ** argv) {
         GGML_ASSERT(type == SERVER_TASK_TYPE_COMPLETION || type == SERVER_TASK_TYPE_INFILL);
 
         auto completion_id = gen_chatcmplid();
-        std::unordered_set<int> task_ids;
+        std::vector<server_task> tasks;
         try {
-            std::vector<server_task> tasks;
-
             const auto & prompt = data.at("prompt");
             // TODO: this log can become very long, put it behind a flag or think about a more compact format
             //SRV_DBG("Prompt: %s\n", prompt.is_string() ? prompt.get<std::string>().c_str() : prompt.dump(2).c_str());
@@ -4303,18 +4297,19 @@ int main(int argc, char ** argv) {
                 task.params.oaicompat_cmpl_id         = completion_id;
                 // oaicompat_model is already populated by params_from_json_cmpl
 
-                tasks.push_back(std::move(task));
+                tasks.push_back(task);
             }
 
-            task_ids = server_task::get_list_id(tasks);
-            ctx_server.queue_results.add_waiting_tasks(tasks);
-            ctx_server.queue_tasks.post(std::move(tasks));
         } catch (const std::exception & e) {
             res_error(res, format_error_response(e.what(), ERROR_TYPE_INVALID_REQUEST));
             return;
         }
 
+        ctx_server.queue_results.add_waiting_tasks(tasks);
+        ctx_server.queue_tasks.post(tasks);
+
         bool stream = json_value(data, "stream", false);
+        const auto task_ids = server_task::get_list_id(tasks);
 
         if (!stream) {
             ctx_server.receive_multi_results(task_ids, [&](std::vector<server_task_result_ptr> & results) {
@@ -4659,9 +4654,8 @@ int main(int argc, char ** argv) {
         // create and queue the task
         json responses = json::array();
         bool error = false;
-        std::unordered_set<int> task_ids;
+        std::vector<server_task> tasks;
         {
-            std::vector<server_task> tasks;
             for (size_t i = 0; i < tokenized_prompts.size(); i++) {
                 server_task task = server_task(SERVER_TASK_TYPE_EMBEDDING);
 
@@ -4673,13 +4667,13 @@ int main(int argc, char ** argv) {
                 task.params.oaicompat = oaicompat;
                 task.params.embd_normalize = embd_normalize;
 
-                tasks.push_back(std::move(task));
+                tasks.push_back(task);
             }
 
-            task_ids = server_task::get_list_id(tasks);
             ctx_server.queue_results.add_waiting_tasks(tasks);
-            ctx_server.queue_tasks.post(std::move(tasks));
         }
+        ctx_server.queue_tasks.post(tasks);
+        std::unordered_set<int> task_ids = server_task::get_list_id(tasks);
 
         // get the result
         ctx_server.receive_multi_results(task_ids, [&](std::vector<server_task_result_ptr> & results) {
@@ -4759,9 +4753,8 @@ int main(int argc, char ** argv) {
         // create and queue the task
         json responses = json::array();
         bool error = false;
-        std::unordered_set<int> task_ids;
+        std::vector<server_task> tasks;
         {
-            std::vector<server_task> tasks;
             auto tokenized_docs = tokenize_input_prompts(ctx_server.vocab, documents, /* add_special */ false, true);
             tasks.reserve(tokenized_docs.size());
             for (size_t i = 0; i < tokenized_docs.size(); i++) {
@@ -4770,13 +4763,13 @@ int main(int argc, char ** argv) {
                 task.id            = ctx_server.queue_tasks.get_new_id();
                 task.index         = i;
                 task.prompt_tokens = server_tokens(tmp, ctx_server.mctx != nullptr);
-                tasks.push_back(std::move(task));
+                tasks.push_back(task);
             }
 
-            task_ids = server_task::get_list_id(tasks);
             ctx_server.queue_results.add_waiting_tasks(tasks);
-            ctx_server.queue_tasks.post(std::move(tasks));
         }
+        ctx_server.queue_tasks.post(tasks);
+        std::unordered_set<int> task_ids = server_task::get_list_id(tasks);
 
         ctx_server.receive_multi_results(task_ids, [&](std::vector<server_task_result_ptr> & results) {
             for (auto & res : results) {
@@ -4825,13 +4818,11 @@ int main(int argc, char ** argv) {
         }
 
         int task_id = ctx_server.queue_tasks.get_new_id();
-        {
-            server_task task(SERVER_TASK_TYPE_SET_LORA);
-            task.id = task_id;
-            task.set_lora = parse_lora_request(ctx_server.params_base.lora_adapters, body);
-            ctx_server.queue_results.add_waiting_task_id(task_id);
-            ctx_server.queue_tasks.post(std::move(task));
-        }
+        server_task task(SERVER_TASK_TYPE_SET_LORA);
+        task.id = task_id;
+        task.set_lora = parse_lora_request(ctx_server.params_base.lora_adapters, body);
+        ctx_server.queue_results.add_waiting_task_id(task_id);
+        ctx_server.queue_tasks.post(task);
 
         // get the result
         server_task_result_ptr result = ctx_server.queue_results.recv(task_id);
@@ -4983,8 +4974,8 @@ int main(int argc, char ** argv) {
         common_chat_templates_source(ctx_server.chat_templates.get()),
         common_chat_format_example(ctx_server.chat_templates.get(), ctx_server.params_base.use_jinja).c_str());
 
-    ctx_server.queue_tasks.on_new_task([&ctx_server](server_task && task) {
-        ctx_server.process_single_task(std::move(task));
+    ctx_server.queue_tasks.on_new_task([&ctx_server](const server_task & task) {
+        ctx_server.process_single_task(task);
     });
 
     ctx_server.queue_tasks.on_update_slots([&ctx_server]() {
diff --git a/tools/server/utils.hpp b/tools/server/utils.hpp
index f3dfc822..8686e3e1 100644
--- a/tools/server/utils.hpp
+++ b/tools/server/utils.hpp
@@ -10,11 +10,11 @@
 #include "chat.h"
 
 // increase max payload length to allow use of larger context size
-#define CPPHTTPLIB_FORM_URL_ENCODED_PAYLOAD_MAX_LENGTH 1048576
+// #define CPPHTTPLIB_FORM_URL_ENCODED_PAYLOAD_MAX_LENGTH 1048576
 // increase backlog size to avoid connection resets for >> 1 slots
 #define CPPHTTPLIB_LISTEN_BACKLOG 512
 // disable Nagle's algorithm
-#define CPPHTTPLIB_TCP_NODELAY true
+// #define CPPHTTPLIB_TCP_NODELAY true
 #include <cpp-httplib/httplib.h>
 
 #define JSON_ASSERT GGML_ASSERT

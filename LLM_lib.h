#pragma once

#include <string>
#include <fstream>
#include <sstream>
#include <vector>
#include <iostream>
#include <setjmp.h>

#include "defs.h"
#include "archchecker.h"
#include "error_handling.h"
#include "LLM.h"

#if defined(__APPLE__)
#include <TargetConditionals.h>
#endif

#if defined(_WIN32)
#include <windows.h>
using LibHandle = HMODULE;
#define LOAD_LIB(path) LoadLibraryA(path)
#define GET_SYM(handle, name) GetProcAddress(handle, name)
#define CLOSE_LIB(handle) FreeLibrary(handle)
#else
#include <dlfcn.h>
using LibHandle = void*;
#define LOAD_LIB(path) dlopen(path, RTLD_LAZY)
#define GET_SYM(handle, name) dlsym(handle, name)
#define CLOSE_LIB(handle) dlclose(handle)
#endif

class UNDREAMAI_API LLMLib : public LLMProvider {
public:
    LLMLib(const std::string& params);
    LLMLib(const char* params);
    LLMLib(int argc, char ** argv);
    ~LLMLib();

    LibHandle handle = nullptr;
    LLMProvider* llm = nullptr;

    //=================================== LLM METHODS START (AUTOGENERATED) ===================================//
    inline std::string handle_tokenize_impl(const json& data) override { return llm->handle_tokenize_impl(data); }
    inline std::string handle_detokenize_impl(const json& data) override { return llm->handle_detokenize_impl(data); }
    inline std::string handle_embeddings_impl(const json& data, httplib::Response* res = nullptr, std::function<bool()> is_connection_closed = always_false) override { return llm->handle_embeddings_impl(data, nullptr, always_false); }
    inline std::string handle_completions_impl(const json& data, CharArrayFn callback = nullptr, httplib::Response* res = nullptr, std::function<bool()> is_connection_closed = always_false, int oaicompat = 0) override { return llm->handle_completions_impl(data, nullptr, nullptr, always_false, 0); }
    inline std::string handle_slots_action_impl(const json& data, httplib::Response* res = nullptr) override { return llm->handle_slots_action_impl(data, nullptr); }
    inline void handle_cancel_action_impl(int id_slot) override { llm->handle_cancel_action_impl(id_slot); }
    inline void init(int argc, char** argv) override { llm->init(argc, argv); }
    inline std::string handle_lora_adapters_apply_impl(const json& data, httplib::Response* res = nullptr) override { return llm->handle_lora_adapters_apply_impl(data, nullptr); }
    inline std::string handle_lora_adapters_list_impl() override { return llm->handle_lora_adapters_list_impl(); }
    inline int get_status() override { return llm->get_status(); }
    inline std::string get_status_message() override { return llm->get_status_message(); }
    inline void start_server() override { llm->start_server(); }
    inline void stop_server() override { llm->stop_server(); }
    inline void join_server() override { llm->join_server(); }
    inline void start_service() override { llm->start_service(); }
    inline void stop_service() override { llm->stop_service(); }
    inline void join_service() override { llm->join_service(); }
    inline void set_SSL(const char* SSL_cert, const char* SSL_key) override { llm->set_SSL(SSL_cert, SSL_key); }
    inline bool is_running() override { return llm->is_running(); }
    inline int embedding_size() override { return llm->embedding_size(); }
    //=================================== LLM METHODS END   (AUTOGENERATED) ===================================//
};

//=================================== HELPERS ===================================//

std::string join_paths(const std::string& a, const std::string& b);
const std::vector<std::string> available_architectures(bool gpu);

//=================================== EXTERNAL API ===================================//

extern "C" {
    UNDREAMAI_API const char* Available_Architectures(bool gpu);
    UNDREAMAI_API LLMLib* LLMLib_Construct(const std::string& command, const std::string& path);
}

cmake_minimum_required(VERSION 3.14)
project("undreamai" C CXX)

set(CMAKE_CUDA_ARCHITECTURES "52;61;70;75;86;89")

add_subdirectory("llama.cpp")
if(DEFINED CMAKE_LIBRARY_OUTPUT_DIRECTORY)
    set_property(DIRECTORY llama.cpp PROPERTY CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_LIBRARY_OUTPUT_DIRECTORY})
endif()

if (NOT WIN32)
    set(STATIC_FLAGS "-fPIC")
    set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} ${STATIC_FLAGS}")
    foreach (target common ggml-base ggml-cpu ggml-amx ggml-blas ggml-cann ggml-cuda ggml-hip ggml-kompute ggml-metal ggml-musa ggml-rpc ggml-sycl ggml-vulkan ggml llama)
        if (TARGET ${target})
            set_target_properties(${target} PROPERTIES COMPILE_FLAGS ${STATIC_FLAGS})
            target_compile_options(${target} PRIVATE -Wno-return-type -Wno-sometimes-uninitialized)
        endif()
    endforeach()
endif()

foreach (target common ggml-cuda ggml-hip ggml-musa)
    if (TARGET ${target})
        target_compile_definitions(${target} PUBLIC GGML_USE_TINYBLAS NDEBUG)
        if(GGML_MINIMIZE_CODE_SIZE)
            target_compile_definitions(${target} PUBLIC GGML_MINIMIZE_CODE_SIZE)
        endif()
        if(GGML_NO_IQUANTS)
            target_compile_definitions(${target} PUBLIC GGML_NO_IQUANTS)
        endif()
    endif()
endforeach()

set(CUDA_NVCC_FLAGS "${CUDA_NVCC_FLAGS} /Zm1000")

set(LIBRARY undreamai)
if(DEFINED LIBRARY_SUFFIX)
  set(LIBRARY "${LIBRARY}_${LIBRARY_SUFFIX}")
endif()

if(CMAKE_SYSTEM_NAME STREQUAL "iOS" OR CMAKE_SYSTEM_NAME STREQUAL "visionOS")
    set(LIBRARY_TYPE STATIC)
else()
    set(LIBRARY_TYPE SHARED)
endif()

add_library(${LIBRARY} ${LIBRARY_TYPE} stringwrapper.cpp log.hpp LLMFunctions.cpp undreamai.cpp error_handling.cpp)
install(TARGETS ${LIBRARY} LIBRARY)
target_include_directories(${LIBRARY} PRIVATE ${CMAKE_CURRENT_SOURCE_DIR} llama.cpp/examples/server llama.cpp)
target_link_libraries(${LIBRARY} PRIVATE common ${CMAKE_THREAD_LIBS_INIT})
target_compile_features(${LIBRARY} PRIVATE cxx_std_11)
add_compile_definitions(${LIBRARY} PRIVATE UNDREAMAI_EXPORTS)


if (BUILD_UNDREAMAI_BINARIES)
    set(TEST undreamai_test)
    add_executable(${TEST} undreamai_test.cpp log.hpp stringwrapper.cpp LLMFunctions.cpp)
    install(TARGETS ${TEST} RUNTIME)
    target_include_directories(${TEST} PRIVATE ${CMAKE_CURRENT_SOURCE_DIR} llama.cpp/examples/server llama.cpp)
    target_link_libraries(${TEST} PRIVATE ${LIBRARY} common ${CMAKE_THREAD_LIBS_INIT})
    target_compile_features(${TEST} PRIVATE cxx_std_11)
    add_compile_definitions(${TEST} PRIVATE UNDREAMAI_EXPORTS)

    set(SERVER undreamai_server)
    add_executable(${SERVER} undreamai_server.cpp log.hpp stringwrapper.cpp LLMFunctions.cpp)
    install(TARGETS ${SERVER} RUNTIME)
    target_include_directories(${SERVER} PRIVATE ${CMAKE_CURRENT_SOURCE_DIR} llama.cpp/examples/server llama.cpp)
    target_link_libraries(${SERVER} PRIVATE ${LIBRARY} common ${CMAKE_THREAD_LIBS_INIT})
    target_compile_features(${SERVER} PRIVATE cxx_std_11)
    add_compile_definitions(${SERVER} PRIVATE UNDREAMAI_EXPORTS)

    if (LLAMA_SERVER_SSL)
        target_link_libraries(${SERVER} PRIVATE OpenSSL::SSL OpenSSL::Crypto)
        target_compile_definitions(${SERVER} PRIVATE CPPHTTPLIB_OPENSSL_SUPPORT)
    endif()
endif()

add_subdirectory(archchecker)
set(DYNAMIC undreamai_dynamic)
add_executable(${DYNAMIC} undreamai_dynamic.cpp LLMFunctions.cpp stringwrapper.cpp error_handling.cpp dynamic_loader.cpp)
install(TARGETS ${DYNAMIC} RUNTIME)
target_include_directories(${DYNAMIC} PRIVATE ${CMAKE_CURRENT_SOURCE_DIR} llama.cpp/common archchecker)
target_link_libraries(${DYNAMIC} PRIVATE FeatureDetector archchecker)
target_compile_features(${DYNAMIC} PRIVATE cxx_std_11)
add_compile_definitions(${DYNAMIC} PRIVATE UNDREAMAI_EXPORTS)


if (WIN32)
    set(CURL_INCLUDE_DIR "${CMAKE_SOURCE_DIR}/curl/include")
    set(CURL_LIBRARY "${CMAKE_SOURCE_DIR}/curl/lib/libcurl_a.lib")
    set(ZLIB_LIBRARY "${CMAKE_SOURCE_DIR}/curl/lib/zlibstatic.lib")
    add_compile_definitions(CURL_STATICLIB)
    find_package(CURL REQUIRED)
endif()

set(CLIENT undreamai_client)
add_executable(${CLIENT} undreamai_client.cpp LLMClient.cpp LLMFunctions.cpp)
install(TARGETS ${CLIENT} RUNTIME)
target_include_directories(${CLIENT} PRIVATE ${CMAKE_CURRENT_SOURCE_DIR} llama.cpp/common ${CURL_INCLUDE_DIR})
target_link_libraries(${CLIENT} PRIVATE ${CURL_LIBRARIES} ${ZLIB_LIBRARY} ws2_32 Wldap32 crypt32 Normaliz )
target_compile_features(${CLIENT} PRIVATE cxx_std_11)
add_compile_definitions(${CLIENT} PRIVATE UNDREAMAI_EXPORTS)

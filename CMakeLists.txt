cmake_minimum_required(VERSION 3.14)
project("undreamai" C CXX)


################################################ CMAKE VARIABLES ################################################

if(CMAKE_SYSTEM_NAME STREQUAL "Windows" OR CMAKE_SYSTEM_NAME STREQUAL "Linux" OR CMAKE_SYSTEM_NAME STREQUAL "Darwin")
    OPTION(LLAMALIB_BUILD_RUNTIME_LIB "Build LlamaLib runtime library" ON)
    OPTION(LLAMALIB_BUILD_SERVER "Build LlamaLib server" ON)
    OPTION(LLAMALIB_BUILD_TESTS "Build LlamaLib tests" ON)
else()
    SET(LLAMALIB_BUILD_SERVER OFF)
    SET(LLAMALIB_BUILD_TESTS OFF)
endif()

SET(LLAMA_BUILD_COMMON ON)
SET(GGML_STATIC ON)
SET(LLAMA_BUILD_TESTS OFF)
SET(LLAMA_BUILD_EXAMPLES OFF)
SET(BUILD_SHARED_LIBS OFF)
SET(LLAMA_CURL OFF)

set(ARCHITECTURE "" CACHE STRING "Target architecture")
if(ARCHITECTURE STREQUAL "noavx")
    SET(GGML_AVX OFF)
    SET(GGML_AVX2 OFF)
    SET(GGML_FMA OFF)
elseif(ARCHITECTURE STREQUAL "avx")
    SET(GGML_AVX2 OFF)
elseif(ARCHITECTURE STREQUAL "avx2")
    # Nothing to define
elseif(ARCHITECTURE STREQUAL "avx512")
    SET(GGML_AVX512 ON)
elseif(ARCHITECTURE STREQUAL "vulkan")
    SET(GGML_VULKAN ON)
elseif(ARCHITECTURE STREQUAL "tinyblas")
    SET(GGML_CUDA ON)
    SET(GGML_MINIMIZE_CODE_SIZE ON)
    SET(GGML_NO_IQUANTS ON)
elseif(ARCHITECTURE STREQUAL "cublas")
    SET(GGML_CUDA ON)
elseif(ARCHITECTURE STREQUAL "hip")
    SET(GGML_HIPBLAS ON)
    SET(AMDGPU_TARGETS "gfx1030,gfx1031,gfx1032,gfx1100,gfx1101,gfx1102")
elseif(ARCHITECTURE STREQUAL "arm64-acc")
    SET(GGML_METAL_EMBED_LIBRARY ON)
    SET(CMAKE_CXX_FLAGS "-march=armv8.2a+dotprod")
elseif(ARCHITECTURE STREQUAL "arm64-no_acc")
    SET(GGML_METAL_EMBED_LIBRARY ON)
    SET(GGML_ACCELERATE OFF)
    SET(GGML_BLAS OFF)
    SET(CMAKE_CXX_FLAGS "-march=armv8.2a+dotprod")
elseif(ARCHITECTURE STREQUAL "x64-acc")
    SET(GGML_METAL OFFF)
elseif(ARCHITECTURE STREQUAL "x64-no_acc")
    SET(GGML_METAL ON)
    SET(GGML_ACCELERATE OFF)
    SET(GGML_BLAS OFF)
elseif(ARCHITECTURE STREQUAL "" AND (CMAKE_SYSTEM_NAME STREQUAL "Windows" OR OS STREQUAL "Linux" OR OS STREQUAL "Darwin"))
    message(FATAL_ERROR "Need to define architecture (ARCHITECTURE)")
else()
    message(FATAL_ERROR "Unknown architecture: ${ARCHITECTURE}")
endif()

if(CMAKE_HOST_SYSTEM_NAME STREQUAL "Darwin")
    SET(GGML_NATIVE ON)
else()
    SET(GGML_NATIVE OFF)
endif()
if(CMAKE_SYSTEM_NAME STREQUAL "Windows" OR CMAKE_SYSTEM_NAME STREQUAL "Linux" OR CMAKE_SYSTEM_NAME STREQUAL "Darwin")
    SET(LLAMA_SERVER_SSL ON)
else()
    SET(LLAMA_SERVER_SSL OFF)
endif()

if(CMAKE_SYSTEM_NAME STREQUAL "Linux")
    SET(CMAKE_BUILD_RPATH_USE_ORIGIN ON)
elseif(CMAKE_SYSTEM_NAME STREQUAL "Darwin")
    SET(LLAMA_FATAL_WARNINGS ON)
    # SET(LLAMA_CURL ON)
elseif(CMAKE_SYSTEM_NAME STREQUAL "Android")
    SET(GGML_OPENMP OFF)
    SET(ANDROID_PLATFORM android-23)
elseif(CMAKE_SYSTEM_NAME STREQUAL "iOS")
    SET(GGML_METAL_EMBED_LIBRARY ON)
    SET(CMAKE_OSX_DEPLOYMENT_TARGET 14.0)
    SET(CMAKE_XCODE_ATTRIBUTE_DEVELOPMENT_TEAM UndreamAI)
elseif(CMAKE_SYSTEM_NAME STREQUAL "visionOS")
    SET(GGML_METAL_EMBED_LIBRARY ON)
    SET(CMAKE_SYSTEM_NAME visionOS)
    SET(CMAKE_OSX_DEPLOYMENT_TARGET 1.0)
    SET(CMAKE_XCODE_ATTRIBUTE_DEVELOPMENT_TEAM UndreamAI)
endif()

 
################################################ SETUP ################################################

# Set CUDA architectures
set(CMAKE_CUDA_ARCHITECTURES "52;61;70;75;86;89")

# Add subdirectories
add_subdirectory("llama.cpp")
add_subdirectory("archchecker")

# Setup CURL
if (WIN32)
    set(CURL_INCLUDE_DIR "${CMAKE_SOURCE_DIR}/curl/include")
    set(CURL_LIBRARY "${CMAKE_SOURCE_DIR}/curl/lib/libcurl_a.lib")
    set(ZLIB_LIBRARY "${CMAKE_SOURCE_DIR}/curl/lib/zlibstatic.lib")
    add_compile_definitions(CURL_STATICLIB)
endif()

find_package(CURL REQUIRED)

set(CURL_LIBRARIES ${CURL_LIBRARIES} ${ZLIB_LIBRARY})
if (WIN32)
    set(CURL_LIBRARIES ${CURL_LIBRARIES} ws2_32 Wldap32 crypt32 Normaliz)
endif()

# Output override
set_property(DIRECTORY llama.cpp PROPERTY CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_LIBRARY_OUTPUT_DIRECTORY})

################################################ llama.cpp COMPILATION ################################################

if (NOT WIN32)
    set(STATIC_FLAGS "-fPIC")
    set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} ${STATIC_FLAGS}")
    foreach (target common ggml-base ggml-cpu ggml-amx ggml-blas ggml-cann ggml-cuda ggml-hip ggml-kompute ggml-metal ggml-musa ggml-rpc ggml-sycl ggml-vulkan ggml llama)
        if (TARGET ${target})
            set_target_properties(${target} PROPERTIES COMPILE_FLAGS ${STATIC_FLAGS})
            target_compile_options(${target} PRIVATE -Wno-return-type -Wno-sometimes-uninitialized)
        endif()
    endforeach()
else()
    add_compile_definitions(WIN32_LEAN_AND_MEAN NOMINMAX)
endif()

foreach (target common ggml-cuda ggml-hip ggml-musa)
    if (TARGET ${target})
        target_compile_definitions(${target} PUBLIC GGML_USE_TINYBLAS NDEBUG)
        if(GGML_MINIMIZE_CODE_SIZE)
            target_compile_definitions(${target} PUBLIC GGML_MINIMIZE_CODE_SIZE)
        endif()
        if(GGML_NO_IQUANTS)
            target_compile_definitions(${target} PUBLIC GGML_NO_IQUANTS)
        endif()
    endif()
endforeach()

set(CUDA_NVCC_FLAGS "${CUDA_NVCC_FLAGS} /Zm1000")

################################################ LLAMALIB ################################################

# helpers
if(CMAKE_SYSTEM_NAME STREQUAL "iOS" OR OS STREQUAL "visionOS")
    set(LIBRARY_TYPE STATIC)
else()
    set(LIBRARY_TYPE SHARED)
endif()

function(common_compile_defs NAME)
    target_compile_features(${NAME} PRIVATE cxx_std_11)
    add_compile_definitions(${NAME} PRIVATE UNDREAMAI_EXPORTS)
    target_include_directories(${NAME} PRIVATE ${CMAKE_CURRENT_SOURCE_DIR} llama.cpp/common llama.cpp/examples/server llama.cpp llama.cpp/include llama.cpp/ggml/include archchecker ${CURL_INCLUDE_DIR})
endfunction()

function(create_library NAME FILES)
    add_library(${NAME} ${LIBRARY_TYPE} ${FILES} LLM.cpp LLM_client.cpp logging.cpp error_handling.cpp)
    target_link_libraries(${NAME} PRIVATE common ${CURL_LIBRARIES})
    common_compile_defs(${NAME})
    install(TARGETS ${NAME} LIBRARY)
endfunction()

function(create_executable NAME LIBRARIES)
    add_executable(${NAME} ${NAME}.cpp)
    target_link_libraries(${NAME} PRIVATE ${LIBRARIES})
    if (LLAMALIB_BUILD_RUNTIME_LIB)
        target_compile_definitions(${NAME} PRIVATE LLAMALIB_BUILD_RUNTIME_LIB)
    endif()
    common_compile_defs(${NAME})
    install(TARGETS ${NAME} RUNTIME)
endfunction()

string(TOLOWER "${CMAKE_SYSTEM_NAME}" OS)
if(CMAKE_SYSTEM_NAME STREQUAL "Darwin")
    SET(OS "macos")
endif()
SET(LIBRARY_NAME "llamalib_${OS}")

# build static library
set(STATIC_LIBRARY ${LIBRARY_NAME})
if(DEFINED ARCHITECTURE)
    set(STATIC_LIBRARY "${LIBRARY_NAME}_${ARCHITECTURE}")
endif()

create_library(${STATIC_LIBRARY} LLM_service.cpp)
target_link_options(${STATIC_LIBRARY} PRIVATE -Wl,--no-undefined)

# build runtime library
if (LLAMALIB_BUILD_RUNTIME_LIB)
    set(RUNTIME_LIBRARY "${LIBRARY_NAME}_runtime")
    create_library(${RUNTIME_LIBRARY} LLM_runtime.cpp)
    target_link_libraries(${RUNTIME_LIBRARY} PRIVATE FeatureDetector archchecker)
endif()

# build executables
if (LLAMALIB_BUILD_SERVER)
    if (LLAMALIB_BUILD_RUNTIME_LIB)
        SET(SERVER_LIB ${RUNTIME_LIBRARY})
    else()
        SET(SERVER_LIB ${STATIC_LIBRARY})
    endif()
    create_executable(llamalib_server ${SERVER_LIB})
    if (LLAMA_SERVER_SSL)
        find_package(OpenSSL REQUIRED)
        target_link_libraries(llamalib_server PRIVATE OpenSSL::SSL OpenSSL::Crypto)
        target_compile_definitions(llamalib_server PRIVATE CPPHTTPLIB_OPENSSL_SUPPORT)
    endif()
endif()

if (LLAMALIB_BUILD_TESTS)
    if (LLAMALIB_BUILD_RUNTIME_LIB)
        SET(TESTS_LIBS "${STATIC_LIBRARY};${RUNTIME_LIBRARY}")
    else()
        SET(TESTS_LIBS ${STATIC_LIBRARY})
    endif()
    create_executable(llamalib_tests "${TESTS_LIBS}")
endif()

# DEBUG VARIABLES
get_cmake_property(_variableNames VARIABLES)
foreach (_variableName ${_variableNames})
    message(STATUS "${_variableName}=${${_variableName}}")
endforeach()

<!-- HTML header for doxygen 1.9.1-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.10.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>LlamaLib: Overview</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="shortcut icon" href="logo_tiny.png" type="image/png">
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<!-- ... other metadata & script includes ... -->
<script type="text/javascript" src="doxygen-awesome-fragment-copy-button.js"></script>
<script type="text/javascript" src="doxygen-awesome-darkmode-toggle.js"></script>
<script type="text/javascript" src="doxygen-awesome-paragraph-link.js"></script>
<script type="text/javascript" src="doxygen-awesome-interactive-toc.js"></script>
<script type="text/javascript">
    DoxygenAwesomeFragmentCopyButton.init()
    DoxygenAwesomeDarkModeToggle.init()
    DoxygenAwesomeParagraphLink.init()
    DoxygenAwesomeInteractiveToc.init()
</script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="custom.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only-darkmode-toggle.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- https://tholman.com/github-corners/ -->
<a href="https://github.com/undreamai/LlamaLib" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo_tiny.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">LlamaLib
   &#160;<span id="projectnumber">v2.0.0</span>
   </div>
   <div id="projectbrief">Cross-platform library for local LLMs</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('index.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Overview </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_README"></a></p>
<h1 align="center"><img src="images/logo.png" alt="" height="150" class="inline"/>  </h1>
<h3 align="center">Cross-Platform High-Level <a class="el" href="classLLM.html" title="Abstract base class for Large Language Model operations.">LLM</a> Library</h3>
<p><a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT" style="pointer-events: none;" class="inline"/></a> <a href="https://discord.gg/RwXKQb6zdv"><img src="https://discordapp.com/api/guilds/1194779009284841552/widget.png?style=shield" alt="" class="inline"/></a> <a href="https://www.reddit.com/user/UndreamAI"><img src="https://img.shields.io/badge/Reddit-%23FF4500.svg?style=flat&amp;logo=Reddit&amp;logoColor=white" alt="Reddit" style="pointer-events: none;" class="inline"/></a> <a href="https://www.linkedin.com/company/undreamai"><img src="https://img.shields.io/badge/LinkedIn-blue?style=flat&amp;logo=linkedin&amp;labelColor=blue" alt="LinkedIn" class="inline"/></a> <a href="https://github.com/undreamai/LlamaLib"><img src="https://img.shields.io/github/stars/undreamai/LlamaLib?style=flat&amp;logo=github&amp;color=f5f5f5" alt="GitHub Repo stars" class="inline"/></a> <a href="https://undream.ai/LlamaLib"><img src="https://img.shields.io/badge/Docs-white.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwEAYAAAAHkiXEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAATqSURBVHic7ZtbiE1RGMc349K4M5EwklwjzUhJCMmTJPJAYjQXJJcH8+Blkry4lPJA8aAoJbekDLmUS6E8SHJL5AW5JPf77eHv93C22Wfttc/ee+0zc/4vv+bMXvusvfZa3/q+b33H80oqqaSSSmqrKnPdgXjUvbvYq5f4+7f486eb/rRajRsn7t4tPngg/vol/vkj/vghXr0q7tghzpyZ//79+on79omXLombNondukXrd9GoSxdx8mSxqUm8eVNkgAvl0aPioEFip07i6dP52z15Ig4fbvVY2VVFhbhokXjrlogJiWvAg/jwoXjqVO73+leUny9eiFVV5mfMlLDRBw+KX76ISQ+0LZ8/F00v4uJFsWPHFh83O+rdWzx3TnQ9wCZ+/Sqyl5iux1RmTu3aiYcPi64H1pasALypoOv4/8SJXraEbXc9kLbECxo2TKyuFj9/zt9u+XIvG8LWv3wpuh5QW86f3/JznT+fv93s2S23C1Z72wbhtH692LdvMvdPSgzkhAkiJhT16ZO/PRPOmcr+Rda4aa5nclTeuZP7PDgRpr1g40bPrQYOFF0PYKHEC+raVVy8OFy7R49EArvURU4mrUAqaTY0iB8/2rXD+XCm5mbR9QAWylevorV7/VpkL0ld06eLpkiyWPj9u93179+LpFZwZ1PXtGnitWui64GMStPmG7SH1NSIJBNHjvTSFZvRvHlise0N9JcBtW1/44Y4dqx45IjnU0JxAGLpklPx+9VZFwPp/9v/eZDGjxcZh7dv4+mXtch+up7Rca+MsJvxiRNi6nvBhg25HWprZMaPGeOlqxEjxGKz+XGRTAAmyJnq6sR370TXA2NLW+8HNjZ62dLOnaLrAQ1r2zmqPH482n0mTfJCKmEvCJHUooNZE/369Elct06kqiKsONRfulTEFDsX8QDlIa5nup9374pE8IiZHPY+ly+LZE/37/cM6mC6IB6Vl4urV6fzfUG6d0/csyf37wsXRFInaM4ckTjGdPg+apTYs6dI3RIWwH//1DV1qkiuxNY2FzrTd+2y6y8z2HQU6efZs+KBAyJZ4v+V0h6ArlwROaQP0uPH4ooV4sqV8Xz/4MF211M2wwoOq1mzRAq5Pnywa5+4KDHE9mI7ly0TO3fOvZ6/eZCoKwB32HS0SMFV1DNtImBKHYstBROoQ4fEQk2RaS+qrxejmj5M7NatIhWARS82xUJfAKahzFcdPnq0GLYgy7Rnbd8e6rGKRyzpuNzPBQty709RcNSZf/KkuHCh2GpMDyKbGNcLYE+YMkVks336NFx7XhTZ3szXiBaqtWvFuAOxM2dEZiyH8UErgc8JLNun7E0aFffSI7RP6owZmz9kSO73HjsmXr8ukppYsybSYyQvBp5QfOjQ3M9tRR496pGgLf1JtLlzRZJzlFzGp4SWDnUxFCrdvy+uWiWa3DJe3N69oj8uSEq8CER88uaNOGBAOv2ILGY69TBBJoM8O0t72zaRoztXBzlLlrT8XARW/IQq82JTMv3mKmv0/9CC4mJMYPwrMSETxAyurRUxQVmXP1fEid7mzeK3b+n2Jzb16CFu2SIWmtNJiriVxANsyq0uoCJfTk4G9y4t24/bSQ0rTkP6gVTG3mz//uKMGSK/ucId5Xe9lZUi5eMMLGUgz56J5Hxu3xZ50Xg3RMIltVn9BRja26PYsBHgAAAAAElFTkSuQmCC" alt="Documentation" style="pointer-events: none;" class="inline"/></a></p>
<p>LlamaLib is a <b>high-level C++ and C#</b> library for running Large Language Models (LLMs) <b>anywhere</b> - from PCs to mobile devices and VR headsets.</p>
<hr  />
<h1><a class="anchor" id="autotoc_md2"></a>
At a glance</h1>
<ul>
<li>‚úÖ <b>High-Level API</b> <br  />
 C++ and C# implementations with intuitive object-oriented design</li>
<li>üì¶ <b>Self-Contained and Embedded</b> <br  />
 Runs embedded within your application. <br  />
 No need for a separate server or external processes. Zero external dependencies.</li>
<li><p class="startli">üåç <b>Runs Anywhere</b> <br  />
 Cross-platform and cross-device. <br  />
 Works on all major platforms:</p><ul>
<li>Desktop: <code>Windows</code>, <code>macOS</code>, <code>Linux</code></li>
<li>Mobile: <code>Android</code>, <code>iOS</code></li>
<li>VR/AR: <code>Meta Quest</code>, <code>Apple Vision</code>, <code>Magic Leap</code></li>
</ul>
<p class="startli">and hardware architectures:</p><ul>
<li>CPU: Intel, AMD, Apple Silicon</li>
<li>GPU: NVIDIA, AMD, Metal</li>
</ul>
</li>
<li>üîç <b>Architecture Detection at runtime</b> <br  />
 Automatically selects the optimal backend at runtime supporting all major GPU and CPU architectures.</li>
<li>ü§è <b>Tiny footprint</b> <br  />
 Integration requires only 10-200 MB depending on the embedded architectures. <br  />
 Custom implementation of tinyBLAS reduces CUDA integration from 1.3GB to 130MB (cuBLAS also supported).</li>
<li>üõ† <b>Production ready</b> <br  />
 Designed for easy integration into C++ and C# applications. <br  />
 Supports both local and client-server deployment.</li>
</ul>
<h2><a class="anchor" id="autotoc_md3"></a>
Why choose LlamaLib?</h2>
<ul>
<li><b>Developer experience</b>: <br  />
 Direct implementation of <a class="el" href="classLLM.html" title="Abstract base class for Large Language Model operations.">LLM</a> operations (completion, tokenisation, embeddings). <br  />
 Clean implementation of <a class="el" href="classLLM.html" title="Abstract base class for Large Language Model operations.">LLM</a> service and clients, server-client architecture and <a class="el" href="classLLM.html" title="Abstract base class for Large Language Model operations.">LLM</a> agents.</li>
<li><b>Universal deployment</b>: <br  />
 LlamaLib is the only library that lets you build your application for any hardware. <br  />
 Unlike alternatives that allow you to only build for specific GPU vendor or CPU-only execution, our architecture detection happens at runtime. <br  />
 If your application is developed for GPU: the GPU backend of the user hardware will be automatically selected (Nvidia, AMD, Metal) or fallback to CPU. <br  />
 CPU detection will automatically identify the CPU hardware (CPU instruction set) of the user to select the optimal backend. <br  />
 LlamaLib works for all platforms from PC to mobile and VR. <br  />
</li>
<li>üõ† <b>Production ready</b> <br  />
 Embeds directly in your application without opening ports or starting external servers. <br  />
 LlamaLib has minimal disk space requirements allowing compact buids e.g. for mobile deployment.</li>
</ul>
<h1><a class="anchor" id="autotoc_md4"></a>
How to help</h1>
<ul>
<li><a href="https://github.com/undreamai/LlamaLib">‚≠ê Star</a> the repo and spread the word!</li>
<li><a href="https://github.com/sponsors/amakropoulos"><img src="https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub&amp;color=%23fe8e86" alt="" class="inline"/></a> developent!</li>
<li>Join our <a href="https://discord.gg/RwXKQb6zdv">Discord</a> community.</li>
<li>Contribute with feature requests, bug reports, or pull requests.</li>
</ul>
<h1><a class="anchor" id="autotoc_md5"></a>
Projects using LlamaLib</h1>
<ul>
<li><a href="https://github.com/undreamai/LLMUnity">LLM for Unity</a>: The most widely used solution to integate LLMs in games</li>
</ul>
<h1><a class="anchor" id="autotoc_md6"></a>
API</h1>
<p>LlamaLib can be used with just a few lines of code. <br  />
</p>
<p>The main classes are:</p><ul>
<li><b><a class="el" href="classLLMService.html" title="Runtime loader for LLM libraries.">LLMService</a></b>: Implementation of the <a class="el" href="classLLM.html" title="Abstract base class for Large Language Model operations.">LLM</a> service. For desktop environments it implements runtime detection with multiple GPU and CPU backends.</li>
<li><b><a class="el" href="classLLMClient.html" title="Client for accessing LLM functionality locally or remotely.">LLMClient</a></b>: Implementation of local or remote clients</li>
<li><b><a class="el" href="classLLMAgent.html" title="High-level conversational agent for LLM interactions.">LLMAgent</a></b>: High-level conversational AI with persistent chat history</li>
</ul>
<p>Core functionality:</p><ul>
<li><a class="el" href="classLLM.html" title="Abstract base class for Large Language Model operations.">LLM</a> core methods: completion, embeddings, tokenization, LORAs</li>
<li>Agent functionality: chat template formatting, chat history</li>
<li>Server-client functionality: start/stop server, connect to local/remote server, SSL and authentication support</li>
</ul>
<p>The methods API can be found here: <br  />
</p><ul>
<li>C++ API</li>
<li>C# API</li>
</ul>
<p>and basic examples here: <br  />
</p><ul>
<li><a href="examples/cpp">C++ examples</a></li>
<li><a href="examples/csharp">C# examples</a></li>
</ul>
<p><b>More detailed documentation</b> on function level can be found on the docs: <a href="https://undream.ai/LlamaLib"><img src="https://img.shields.io/badge/Documentation-white.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwEAYAAAAHkiXEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAATqSURBVHic7ZtbiE1RGMc349K4M5EwklwjzUhJCMmTJPJAYjQXJJcH8+Blkry4lPJA8aAoJbekDLmUS6E8SHJL5AW5JPf77eHv93C22Wfttc/ee+0zc/4vv+bMXvusvfZa3/q+b33H80oqqaSSSmqrKnPdgXjUvbvYq5f4+7f486eb/rRajRsn7t4tPngg/vol/vkj/vghXr0q7tghzpyZ//79+on79omXLombNondukXrd9GoSxdx8mSxqUm8eVNkgAvl0aPioEFip07i6dP52z15Ig4fbvVY2VVFhbhokXjrlogJiWvAg/jwoXjqVO73+leUny9eiFVV5mfMlLDRBw+KX76ISQ+0LZ8/F00v4uJFsWPHFh83O+rdWzx3TnQ9wCZ+/Sqyl5iux1RmTu3aiYcPi64H1pasALypoOv4/8SJXraEbXc9kLbECxo2TKyuFj9/zt9u+XIvG8LWv3wpuh5QW86f3/JznT+fv93s2S23C1Z72wbhtH692LdvMvdPSgzkhAkiJhT16ZO/PRPOmcr+Rda4aa5nclTeuZP7PDgRpr1g40bPrQYOFF0PYKHEC+raVVy8OFy7R49EArvURU4mrUAqaTY0iB8/2rXD+XCm5mbR9QAWylevorV7/VpkL0ld06eLpkiyWPj9u93179+LpFZwZ1PXtGnitWui64GMStPmG7SH1NSIJBNHjvTSFZvRvHlise0N9JcBtW1/44Y4dqx45IjnU0JxAGLpklPx+9VZFwPp/9v/eZDGjxcZh7dv4+mXtch+up7Rca+MsJvxiRNi6nvBhg25HWprZMaPGeOlqxEjxGKz+XGRTAAmyJnq6sR370TXA2NLW+8HNjZ62dLOnaLrAQ1r2zmqPH482n0mTfJCKmEvCJHUooNZE/369Elct06kqiKsONRfulTEFDsX8QDlIa5nup9374pE8IiZHPY+ly+LZE/37/cM6mC6IB6Vl4urV6fzfUG6d0/csyf37wsXRFInaM4ckTjGdPg+apTYs6dI3RIWwH//1DV1qkiuxNY2FzrTd+2y6y8z2HQU6efZs+KBAyJZ4v+V0h6ArlwROaQP0uPH4ooV4sqV8Xz/4MF211M2wwoOq1mzRAq5Pnywa5+4KDHE9mI7ly0TO3fOvZ6/eZCoKwB32HS0SMFV1DNtImBKHYstBROoQ4fEQk2RaS+qrxejmj5M7NatIhWARS82xUJfAKahzFcdPnq0GLYgy7Rnbd8e6rGKRyzpuNzPBQty709RcNSZf/KkuHCh2GpMDyKbGNcLYE+YMkVks336NFx7XhTZ3szXiBaqtWvFuAOxM2dEZiyH8UErgc8JLNun7E0aFffSI7RP6owZmz9kSO73HjsmXr8ukppYsybSYyQvBp5QfOjQ3M9tRR496pGgLf1JtLlzRZJzlFzGp4SWDnUxFCrdvy+uWiWa3DJe3N69oj8uSEq8CER88uaNOGBAOv2ILGY69TBBJoM8O0t72zaRoztXBzlLlrT8XARW/IQq82JTMv3mKmv0/9CC4mJMYPwrMSETxAyurRUxQVmXP1fEid7mzeK3b+n2Jzb16CFu2SIWmtNJiriVxANsyq0uoCJfTk4G9y4t24/bSQ0rTkP6gVTG3mz//uKMGSK/ucId5Xe9lZUi5eMMLGUgz56J5Hxu3xZ50Xg3RMIltVn9BRja26PYsBHgAAAAAElFTkSuQmCC" alt="" style="pointer-events: none;" class="inline"/></a></p>
<h1><a class="anchor" id="autotoc_md7"></a>
Quick Start</h1>
<h2><a class="anchor" id="autotoc_md8"></a>
(C++)</h2>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="LlamaLib_8h.html">LlamaLib.h</a>&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">// LlamaLib automatically detects your hardware and selects optimal backend</span></div>
<div class="line"><a class="code hl_class" href="classLLMService.html">LLMService</a> llm(<span class="stringliteral">&quot;path/to/model.gguf&quot;</span>);</div>
<div class="line"><span class="comment">/* You can also specify:</span></div>
<div class="line"><span class="comment">  threads=-1,        // number of CPU threads to use</span></div>
<div class="line"><span class="comment">  gpu_layers=0,      // number of layers to offload to GPU (if 0, GPU is not used),</span></div>
<div class="line"><span class="comment">  num_slots=1     // number of slots / clients supported in parallel</span></div>
<div class="line"><span class="comment">*/</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">// Start service</span></div>
<div class="line">llm.start();</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Generate completion</span></div>
<div class="line">std::string response = llm.completion(<span class="stringliteral">&quot;Hello, how are you?&quot;</span>);</div>
<div class="line">std::cout &lt;&lt; response &lt;&lt; std::endl;</div>
<div class="ttc" id="aLlamaLib_8h_html"><div class="ttname"><a href="LlamaLib_8h.html">LlamaLib.h</a></div><div class="ttdoc">Main include file for the LLama library.</div></div>
<div class="ttc" id="aclassLLMService_html"><div class="ttname"><a href="classLLMService.html">LLMService</a></div><div class="ttdoc">Runtime loader for LLM libraries.</div><div class="ttdef"><b>Definition</b> <a href="LLM__runtime_8h_source.html#l00062">LLM_runtime.h:63</a></div></div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md9"></a>
C</h2>
<div class="fragment"><div class="line"><span class="keyword">using </span>LlamaLib;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Same API, different language</span></div>
<div class="line"><a class="code hl_class" href="classLLMService.html">LLMService</a> llm = <span class="keyword">new</span> <a class="code hl_class" href="classLLMService.html">LLMService</a>(<span class="stringliteral">&quot;path/to/model.gguf&quot;</span>);</div>
<div class="line"><span class="comment">/* You can also specify:</span></div>
<div class="line"><span class="comment">  threads=-1,        // number of CPU threads to use</span></div>
<div class="line"><span class="comment">  gpu_layers=0,      // number of layers to offload to GPU (if 0, GPU is not used),</span></div>
<div class="line"><span class="comment">  num_slots=1     // number of slots / clients supported in parallel</span></div>
<div class="line"><span class="comment">*/</span></div>
<div class="line">llm.Start();</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">string</span> response = llm.Completion(<span class="stringliteral">&quot;Hello, how are you?&quot;</span>);</div>
<div class="line">Console.WriteLine(response);</div>
</div><!-- fragment --> </div></div><!-- PageDoc -->
<a href="doxygen_crawl.html"/>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.10.0 </li>
  </ul>
</div>
</body>
</html>
